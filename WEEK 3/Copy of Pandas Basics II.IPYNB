{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Pandas Basics II","provenance":[{"file_id":"1AUxj8z1mPfXib-Vmw8PJDQm0eOBrjvKm","timestamp":1620885177068}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9I110jHWZkwL"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"YW4SN5OupJfN"},"source":["# Pandas Basics II\n"]},{"cell_type":"markdown","metadata":{"id":"v2Rb2q_Epd9P"},"source":["## 1.0 Importing the Libraries to be used "]},{"cell_type":"code","metadata":{"id":"frw-YOvjpCiw","executionInfo":{"status":"ok","timestamp":1621156589093,"user_tz":-180,"elapsed":2544,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Let's import the pandas library\n","#\n","# OUR CODE GOES HERE\n","import pandas as pd\n","# as well as the Numpy library\n","import numpy as np\n","\n","# OUR CODE GOES HERE"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5b5cMg9vpg3D"},"source":["## 1.1 Loading our Datasets"]},{"cell_type":"code","metadata":{"id":"-9gmYBvxptCI","colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"status":"ok","timestamp":1620929525089,"user_tz":-180,"elapsed":1218,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqKSK4J8lnl6SOKjJuSU2EvE6d9rIJCmC9oA82=s64","userId":"01120465740264942012"}},"outputId":"f1cbd952-12b0-4361-f912-5195d1a640a8"},"source":["# Example 1\n","# We will begin learning how we can load datasets from different types of sources\n","# Let's first begin with loading datasets from a JSON file \n","#\n","\n","\n","# First, we get the URL to the JSON file (alternatively this can be a filepath)\n","url = 'https://raw.githubusercontent.com/algolia/datasets/master/airports/airports.json'\n","\n","# Then load, the first sheet of the JSON file into a data frame. \n","# We are going to use pandas read_json method. This method works the same as read_csv. You can read more about it from the documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html\n","df = pd.read_json(url, orient='columns')\n","\n","# Lastly, view the first ten rows\n","df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>city</th>\n","      <th>country</th>\n","      <th>iata_code</th>\n","      <th>_geoloc</th>\n","      <th>links_count</th>\n","      <th>objectID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hartsfield Jackson Atlanta Intl</td>\n","      <td>Atlanta</td>\n","      <td>United States</td>\n","      <td>ATL</td>\n","      <td>{'lat': 33.636719, 'lng': -84.428067}</td>\n","      <td>1826</td>\n","      <td>3682</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Chicago Ohare Intl</td>\n","      <td>Chicago</td>\n","      <td>United States</td>\n","      <td>ORD</td>\n","      <td>{'lat': 41.978603, 'lng': -87.904842}</td>\n","      <td>1108</td>\n","      <td>3830</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Capital Intl</td>\n","      <td>Beijing</td>\n","      <td>China</td>\n","      <td>PEK</td>\n","      <td>{'lat': 40.080111, 'lng': 116.584556}</td>\n","      <td>1069</td>\n","      <td>3364</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Heathrow</td>\n","      <td>London</td>\n","      <td>United Kingdom</td>\n","      <td>LHR</td>\n","      <td>{'lat': 51.4775, 'lng': -0.461389}</td>\n","      <td>1051</td>\n","      <td>507</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Charles De Gaulle</td>\n","      <td>Paris</td>\n","      <td>France</td>\n","      <td>CDG</td>\n","      <td>{'lat': 49.012779, 'lng': 2.55}</td>\n","      <td>1041</td>\n","      <td>1382</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Los Angeles Intl</td>\n","      <td>Los Angeles</td>\n","      <td>United States</td>\n","      <td>LAX</td>\n","      <td>{'lat': 33.942536, 'lng': -118.408075}</td>\n","      <td>990</td>\n","      <td>3484</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Frankfurt Main</td>\n","      <td>Frankfurt</td>\n","      <td>Germany</td>\n","      <td>FRA</td>\n","      <td>{'lat': 50.026421, 'lng': 8.543125}</td>\n","      <td>990</td>\n","      <td>340</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Dallas Fort Worth Intl</td>\n","      <td>Dallas-Fort Worth</td>\n","      <td>United States</td>\n","      <td>DFW</td>\n","      <td>{'lat': 32.896828, 'lng': -97.037997}</td>\n","      <td>936</td>\n","      <td>3670</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>John F Kennedy Intl</td>\n","      <td>New York</td>\n","      <td>United States</td>\n","      <td>JFK</td>\n","      <td>{'lat': 40.639751, 'lng': -73.778925}</td>\n","      <td>911</td>\n","      <td>3797</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Schiphol</td>\n","      <td>Amsterdam</td>\n","      <td>Netherlands</td>\n","      <td>AMS</td>\n","      <td>{'lat': 52.308613, 'lng': 4.763889}</td>\n","      <td>903</td>\n","      <td>580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              name               city  ... links_count objectID\n","0  Hartsfield Jackson Atlanta Intl            Atlanta  ...        1826     3682\n","1               Chicago Ohare Intl            Chicago  ...        1108     3830\n","2                     Capital Intl            Beijing  ...        1069     3364\n","3                         Heathrow             London  ...        1051      507\n","4                Charles De Gaulle              Paris  ...        1041     1382\n","5                 Los Angeles Intl        Los Angeles  ...         990     3484\n","6                   Frankfurt Main          Frankfurt  ...         990      340\n","7           Dallas Fort Worth Intl  Dallas-Fort Worth  ...         936     3670\n","8              John F Kennedy Intl           New York  ...         911     3797\n","9                         Schiphol          Amsterdam  ...         903      580\n","\n","[10 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"xaY5MQdxptu0","colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"status":"ok","timestamp":1620929719756,"user_tz":-180,"elapsed":1509,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqKSK4J8lnl6SOKjJuSU2EvE6d9rIJCmC9oA82=s64","userId":"01120465740264942012"}},"outputId":"450a3744-ff9d-43ac-e88d-17a162e3f901"},"source":["# Example 2\n","# We can also load an Excel file as shown below\n","# \n","\n","# We create a URL to Excel file (alternatively this can be a filepath)\n","url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.xlsx'\n","\n","# Then load the first sheet of the Excel file into a data frame\n","df = pd.read_excel(url, sheet_name=0, header=1)\n","\n","# Lastly, view the first ten rows\n","df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>5</th>\n","      <th>2015-01-01 00:00:00</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>2015-01-01 00:00:01</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>2015-01-01 00:00:02</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>2015-01-01 00:00:03</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>2015-01-01 00:00:04</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>2015-01-01 00:00:05</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7</td>\n","      <td>2015-01-01 00:00:06</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>2015-01-01 00:00:07</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6</td>\n","      <td>2015-01-01 00:00:08</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>2015-01-01 00:00:09</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5</td>\n","      <td>2015-01-01 00:00:10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   5 2015-01-01 00:00:00  0\n","0  5 2015-01-01 00:00:01  0\n","1  9 2015-01-01 00:00:02  0\n","2  6 2015-01-01 00:00:03  0\n","3  6 2015-01-01 00:00:04  0\n","4  9 2015-01-01 00:00:05  0\n","5  7 2015-01-01 00:00:06  0\n","6  1 2015-01-01 00:00:07  0\n","7  6 2015-01-01 00:00:08  0\n","8  9 2015-01-01 00:00:09  0\n","9  5 2015-01-01 00:00:10  0"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"sfmKllkvptir","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621159398342,"user_tz":-180,"elapsed":1239,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"bf5daae4-479b-4d44-9d85-e0923f46e6e3"},"source":["# Example 3\n","# We can also load A CSV Into pandas\n","# \n","\n","# We create a csv file or import from a url\n","\n","# First, creating a dataframe (that we will be importing)\n","raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'last_name': ['Miller', 'Jacobson', \".\", 'Milner', 'Cooze'], \n","        'age': [42, 52, 36, 24, 73], \n","        'preTestScore': [4, 24, 31, \".\", \".\"],\n","        'postTestScore': [\"25,000\", \"94,000\", 57, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Saving the above dataframe as csv in the working directory\n","df.to_csv('example.csv')\n","\n","# Loading a csv\n","df = pd.read_csv('example.csv')\n","df\n","\n","# Loading a csv with no headers\n","# Uncomment the lines below after running previous lines.\n","df = pd.read_csv('example.csv', header=None) \n","df\n","\n","# Loading a csv while specifying column names\n","#Uncomment the lines below after running previous lines.\n","df = pd.read_csv('example.csv', names=['UID', 'First Name', 'Last Name', 'Age', 'Pre-Test Score', 'Post-Test Score'])\n","df\n","\n","# Loading a csv while setting the index columns to First Name and Last Name\n","# Uncomment the lines below after running previous lines.\n","df = pd.read_csv('example.csv', index_col=['First Name', 'Last Name'], names=['UID', 'First Name', 'Last Name', 'Age', 'Pre-Test Score', 'Post-Test Score'])\n","df\n","\n","# Loading a csv while specifying “.” and “NA” as missing values in the Last Name column and “.” as missing values in Pre-Test Score column\n","# Uncomment the lines below after running previous lines.\n","sentinels = {'Last Name': ['.', 'NA'], 'Pre-Test Score': ['.']}\n","df = pd.read_csv('example.csv', na_values=sentinels)\n","df"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>preTestScore</th>\n","      <th>postTestScore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Jason</td>\n","      <td>Miller</td>\n","      <td>42</td>\n","      <td>4</td>\n","      <td>25,000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Molly</td>\n","      <td>Jacobson</td>\n","      <td>52</td>\n","      <td>24</td>\n","      <td>94,000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Tina</td>\n","      <td>.</td>\n","      <td>36</td>\n","      <td>31</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Jake</td>\n","      <td>Milner</td>\n","      <td>24</td>\n","      <td>.</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Amy</td>\n","      <td>Cooze</td>\n","      <td>73</td>\n","      <td>.</td>\n","      <td>70</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 first_name last_name  age preTestScore postTestScore\n","0           0      Jason    Miller   42            4        25,000\n","1           1      Molly  Jacobson   52           24        94,000\n","2           2       Tina         .   36           31            57\n","3           3       Jake    Milner   24            .            62\n","4           4        Amy     Cooze   73            .            70"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"juUUmvj5r1U1"},"source":["### <font color=\"green\">1.1 Challenges</font>"]},{"cell_type":"code","metadata":{"id":"4OSrlmj2r-vR","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1620931011422,"user_tz":-180,"elapsed":1345,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqKSK4J8lnl6SOKjJuSU2EvE6d9rIJCmC9oA82=s64","userId":"01120465740264942012"}},"outputId":"e59402b3-1699-4103-b88a-1039d465a3eb"},"source":["# Challenge 1\n","# Load the first 10 records of the JSON file from the following url\n","url = \"https://raw.githubusercontent.com/dariusk/corpora/master/data/books/academic_subjects.json\"\n","# \n","df = pd.read_json(url, orient='columns')\n","\n","df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>description</th>\n","      <th>source</th>\n","      <th>subjects</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Accounting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Administration of Special Education</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Adult &amp; Continuing Teacher Education</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Advertising</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>African Studies</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Afro-American Studies</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Agricultural Economics</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Agricultural Engineering</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Agronomy &amp; Crop Science</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Academic subjects</td>\n","      <td>Classification of Instructional Programs (CIP ...</td>\n","      <td>Native American Studies</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         description  ...                              subjects\n","0  Academic subjects  ...                            Accounting\n","1  Academic subjects  ...   Administration of Special Education\n","2  Academic subjects  ...  Adult & Continuing Teacher Education\n","3  Academic subjects  ...                           Advertising\n","4  Academic subjects  ...                       African Studies\n","5  Academic subjects  ...                 Afro-American Studies\n","6  Academic subjects  ...                Agricultural Economics\n","7  Academic subjects  ...              Agricultural Engineering\n","8  Academic subjects  ...               Agronomy & Crop Science\n","9  Academic subjects  ...               Native American Studies\n","\n","[10 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"YLAQVIq-sAWZ","colab":{"base_uri":"https://localhost:8080/","height":804},"executionInfo":{"status":"ok","timestamp":1620931118918,"user_tz":-180,"elapsed":6414,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqKSK4J8lnl6SOKjJuSU2EvE6d9rIJCmC9oA82=s64","userId":"01120465740264942012"}},"outputId":"582dfee5-04b9-4e85-88ab-4ae328e5673b"},"source":["# Challenge 2\n","# Preview the excel spreadsheet from the following url\n","url = \"http://ww2.amstat.org/publications/jse/v20n3/delzell/conflictdata.xlsx\"\n","# \n","df = pd.read_excel(url, sheet_name=0, header=1)\n","\n","df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2005</th>\n","      <th>Riots</th>\n","      <th>Protesters (Algeria)</th>\n","      <th>Unnamed: 3</th>\n","      <th>Algeria</th>\n","      <th>Chlef</th>\n","      <th>Sidi Ammar</th>\n","      <th>36.47</th>\n","      <th>1.45</th>\n","      <th>604300</th>\n","      <th>20050125</th>\n","      <th>35.79</th>\n","      <th>MILIANA</th>\n","      <th>2.23</th>\n","      <th>36.29</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2003</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>NaN</td>\n","      <td>Algeria</td>\n","      <td>NaN</td>\n","      <td>Tadjenanet</td>\n","      <td>36.11</td>\n","      <td>5.98</td>\n","      <td>604680</td>\n","      <td>20030201</td>\n","      <td>38.50</td>\n","      <td>BATNA</td>\n","      <td>6.31</td>\n","      <td>35.75</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2002</td>\n","      <td>Battles</td>\n","      <td>Military Forces of Ethiopia (1991-)</td>\n","      <td>ONLF: Ogaden National Liberation Front</td>\n","      <td>Ethiopia</td>\n","      <td>Degeh Bur</td>\n","      <td>Afweyne</td>\n","      <td>9.38</td>\n","      <td>43.06</td>\n","      <td>696754</td>\n","      <td>20020224</td>\n","      <td>39.20</td>\n","      <td>CAMP LEMONIER</td>\n","      <td>43.15</td>\n","      <td>11.55</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2003</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>Police Forces of Algeria (1999-)</td>\n","      <td>Algeria</td>\n","      <td>Bordj Bou Arreridj</td>\n","      <td>Bordj Bou Arerridj</td>\n","      <td>36.07</td>\n","      <td>4.77</td>\n","      <td>604440</td>\n","      <td>20030217</td>\n","      <td>39.40</td>\n","      <td>BORDJ-BOU-ARRERIDJ</td>\n","      <td>4.76</td>\n","      <td>36.06</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1999</td>\n","      <td>Violence against civilians</td>\n","      <td>GIA: Armed Islamic Group of Algeria</td>\n","      <td>Civilians (Algeria)</td>\n","      <td>Algeria</td>\n","      <td>Relizane</td>\n","      <td>Relizane</td>\n","      <td>35.74</td>\n","      <td>0.55</td>\n","      <td>605060</td>\n","      <td>19991217</td>\n","      <td>39.90</td>\n","      <td>MASCARA-MATEMORE</td>\n","      <td>0.30</td>\n","      <td>35.59</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2005</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>NaN</td>\n","      <td>Algeria</td>\n","      <td>Bordj Bou Arreridj</td>\n","      <td>Bordj Bou Arreridj</td>\n","      <td>36.07</td>\n","      <td>4.77</td>\n","      <td>604440</td>\n","      <td>20050125</td>\n","      <td>39.90</td>\n","      <td>BORDJ-BOU-ARRERIDJ</td>\n","      <td>4.76</td>\n","      <td>36.06</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2006</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>Police Forces of Algeria (1999-)</td>\n","      <td>Algeria</td>\n","      <td>Djelfa</td>\n","      <td>Djelfa</td>\n","      <td>34.66</td>\n","      <td>3.25</td>\n","      <td>605350</td>\n","      <td>20060206</td>\n","      <td>40.09</td>\n","      <td>DJELFA</td>\n","      <td>3.38</td>\n","      <td>34.33</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2002</td>\n","      <td>Violence against civilians</td>\n","      <td>GIA: Armed Islamic Group of Algeria</td>\n","      <td>Civilians (Algeria)</td>\n","      <td>Algeria</td>\n","      <td>Blida</td>\n","      <td>Blida</td>\n","      <td>36.46</td>\n","      <td>2.82</td>\n","      <td>604370</td>\n","      <td>20020207</td>\n","      <td>41.00</td>\n","      <td>MEDEA</td>\n","      <td>2.73</td>\n","      <td>36.28</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2003</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>NaN</td>\n","      <td>Algeria</td>\n","      <td>Kabylie</td>\n","      <td>Kabylie</td>\n","      <td>36.25</td>\n","      <td>5.00</td>\n","      <td>604450</td>\n","      <td>20030113</td>\n","      <td>41.00</td>\n","      <td>SETIF</td>\n","      <td>5.25</td>\n","      <td>36.18</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2005</td>\n","      <td>Riots</td>\n","      <td>Protesters (Algeria)</td>\n","      <td>NaN</td>\n","      <td>Algeria</td>\n","      <td>Tiaret Province</td>\n","      <td>Tiaret</td>\n","      <td>35.37</td>\n","      <td>1.31</td>\n","      <td>605110</td>\n","      <td>20050125</td>\n","      <td>41.90</td>\n","      <td>TIARET</td>\n","      <td>1.46</td>\n","      <td>35.34</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1997</td>\n","      <td>Violence against civilians</td>\n","      <td>GIA: Armed Islamic Group of Algeria</td>\n","      <td>Civilians (Algeria)</td>\n","      <td>Algeria</td>\n","      <td>Tipaza</td>\n","      <td>Hadjout</td>\n","      <td>36.51</td>\n","      <td>2.41</td>\n","      <td>604300</td>\n","      <td>19970104</td>\n","      <td>43.29</td>\n","      <td>MILIANA</td>\n","      <td>2.23</td>\n","      <td>36.29</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   2005                       Riots  ...  36.29  C\n","0  2003                       Riots  ...  35.75  C\n","1  2002                     Battles  ...  11.55  C\n","2  2003                       Riots  ...  36.06  C\n","3  1999  Violence against civilians  ...  35.59  C\n","4  2005                       Riots  ...  36.06  C\n","5  2006                       Riots  ...  34.33  C\n","6  2002  Violence against civilians  ...  36.28  C\n","7  2003                       Riots  ...  36.18  C\n","8  2005                       Riots  ...  35.34  C\n","9  1997  Violence against civilians  ...  36.29  C\n","\n","[10 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"obhaE1tisAOE","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621158598882,"user_tz":-180,"elapsed":1153,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"18bee8cc-5776-4193-de25-865e00c6a155"},"source":["# Challenge 3\n","# Download and upload the csv file from this url (http://bit.ly/NairobiBusesDataset) (Not Load from Url)\n","# Then preview the dataset while specifying column names \n","# \n","df = pd.read_csv(\"/content/buses-western-Nairobi - buses-western-Nairobi.csv\")\n","df[['ride_id','seat_number','payment_method','travel_time']].head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ride_id</th>\n","      <th>seat_number</th>\n","      <th>payment_method</th>\n","      <th>travel_time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1442</td>\n","      <td>15A</td>\n","      <td>Mpesa</td>\n","      <td>7:15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5437</td>\n","      <td>14A</td>\n","      <td>Mpesa</td>\n","      <td>7:12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5710</td>\n","      <td>8B</td>\n","      <td>Mpesa</td>\n","      <td>7:05</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5777</td>\n","      <td>19A</td>\n","      <td>Mpesa</td>\n","      <td>7:10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5778</td>\n","      <td>11A</td>\n","      <td>Mpesa</td>\n","      <td>7:12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ride_id seat_number payment_method travel_time\n","0     1442         15A          Mpesa        7:15\n","1     5437         14A          Mpesa        7:12\n","2     5710          8B          Mpesa        7:05\n","3     5777         19A          Mpesa        7:10\n","4     5778         11A          Mpesa        7:12"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"Uk1pYV6pbTEK","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1621159701414,"user_tz":-180,"elapsed":4774,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"144a2926-a553-4569-fe2c-33445561109d"},"source":["# Challenge 4 \n","# Create a Dataframe from the following dictionary then fill in the missing values with \".\"\n","#\n","\n","# Dictionary\n","dict = {'First Score':[100, 90, np.nan, 95], \n","        'Second Score': [30, 45, 56, np.nan], \n","        'Third Score':[np.nan, 40, 80, 98]} \n","#sentinels = {'Firt Score': ['NaN'],'Second Score':['np.nan'],'Third Score':['np.nan']}\n","df=pd.DataFrame(dict)\n","df.fillna('.')\n"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>First Score</th>\n","      <th>Second Score</th>\n","      <th>Third Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100</td>\n","      <td>30</td>\n","      <td>.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>90</td>\n","      <td>45</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>.</td>\n","      <td>56</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>95</td>\n","      <td>.</td>\n","      <td>98</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  First Score Second Score Third Score\n","0         100           30           .\n","1          90           45          40\n","2           .           56          80\n","3          95            .          98"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"UvgWwvdBpxIF"},"source":["## 1.2 Exploration"]},{"cell_type":"code","metadata":{"id":"3E_v5OjSpzZa","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1621161139434,"user_tz":-180,"elapsed":1121,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"e3b04c07-1044-40d9-d7cd-657e3cfa2f2a"},"source":["# Example 1\n","# We will now see how we can filter pandas Dataframes as shown below\n","# \n","\n","# Creating the following Dataframe\n","data = {'name': ['Kevin', 'Jane', 'Mary', 'Jared', 'Elizabeth'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [4, 24, 31, 2, 3],\n","        'coverage': [25, 94, 57, 62, 70]}\n","df = pd.DataFrame(data, index = ['Nairobi', 'Nakuru', 'Kisumu', 'Kericho', 'Eldoret'])\n","df\n","\n","# Viewing a column\n","# Uncomment the line below after running previous line\n","df['name']\n","\n","# Viewing two Columns\n","# Uncomment the line below after running previous line\n","df[['name', 'reports']]\n","\n","# Viewing the first two Rows\n","# Uncomment the line below after running previous line\n","df[:2]\n","\n","# Viewing rows where coverage is greater than 50\n","# Uncomment the line below after running previous line\n","df[df['coverage'] > 50]\n","\n","\n","# Viewing rows where coverage is greater than 50 and reports less than 4\n","# Uncomment the line below after running previous line\n","df[(df['coverage']  > 50) & (df['reports'] < 4)]"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","      <th>coverage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Nairobi</th>\n","      <td>Kevin</td>\n","      <td>2012</td>\n","      <td>4</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>Nakuru</th>\n","      <td>Jane</td>\n","      <td>2012</td>\n","      <td>24</td>\n","      <td>94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          name  year  reports  coverage\n","Nairobi  Kevin  2012        4        25\n","Nakuru    Jane  2012       24        94"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"_R-B-0cwp0t5"},"source":["# Example 2\n","# Then find the largest value in a Dataframe column\n","# \n","\n","# First creating a Dataframe\n","raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n","        'age': [42, 52, 36, 24, 73], \n","        'preTestScore': [4, 24, 31, 2, 3],\n","        'postTestScore': [25, 94, 57, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Then Indexing of the row with the highest value in the preTestScore column\n","# Uncomment the line below after running previous line\n","df['preTestScore'].max()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esmZmojypz0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621161816338,"user_tz":-180,"elapsed":1033,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"9530558e-ca95-4642-c28f-b36a865acd2b"},"source":["# Example 3\n","# Finding also Unique Values In the Pandas Dataframes\n","import numpy as np\n","\n","# First creating a Dataframe from a Dictionary\n","raw_data = {'regiment': ['51st', '29th', '2nd', '19th', '12th', '101st', '90th', '30th', '193th', '1st', '94th', '91th'], \n","            'trucks': ['MAZ-7310', np.nan, 'MAZ-7310', 'MAZ-7310', 'Tatra 810', 'Tatra 810', 'Tatra 810', 'Tatra 810', 'ZIS-150', 'Tatra 810', 'ZIS-150', 'ZIS-150'],\n","            'tanks': ['Merkava Mark 4', 'Merkava Mark 4', 'Merkava Mark 4', 'Leopard 2A6M', 'Leopard 2A6M', 'Leopard 2A6M', 'Arjun MBT', 'Leopard 2A6M', 'Arjun MBT', 'Arjun MBT', 'Arjun MBT', 'Arjun MBT'],\n","            'aircraft': ['none', 'none', 'none', 'Harbin Z-9', 'Harbin Z-9', 'none', 'Harbin Z-9', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk', 'SH-60B Seahawk']}\n","df = pd.DataFrame(raw_data, columns = ['regiment', 'trucks', 'tanks', 'aircraft'])\n","df\n","\n","# Viewing the top few rows\n","# Uncomment the line below after running previous lines\n","df.head()\n","\n","# We can create a list of unique values by turning the pandas column into a set\n","# Uncomment the line below after running previous lines\n","list(set(df.trucks))\n","\n","# Here's another way of creating a list of unique values in df.trucks\n","# Uncomment the line below after running previous lines\n","list(df['trucks'].unique())\n"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['MAZ-7310', nan, 'Tatra 810', 'ZIS-150']"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"B3RH0pXqqRbH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621161913813,"user_tz":-180,"elapsed":4764,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"fed39ce7-c2c3-4926-a61b-888a3cd2e88f"},"source":["# Example 4\n","# listing Unique Values In A pandas Column\n","#\n","\n","# Create an example dataframe\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [4, 24, 31, 2, 3]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n","\n","# List unique values in the df['name'] column\n","# Uncomment the line below after running previous lines\n","df.name.unique()"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"QcCOrEo5qpfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621162255769,"user_tz":-180,"elapsed":1207,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"ccc718ee-7e95-4bda-91aa-e1711fb46503"},"source":["# Example 5\n","# Grouping Rows In pandas\n","# \n","\n","# Creating a Dataframe\n","raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n","        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n","        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n","        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n","        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Creating a grouping object. In other words, create an object that\n","# represents that particular grouping. In this case we group\n","# pre-test scores by the regiment.\n","# Uncomment the line below after running previous lines\n","regiment_preScore = df['preTestScore'].groupby(df['regiment'])\n","# Displaying the mean value of the each regiment's pre-test score\n","# Uncomment the line below after running previous lines\n","regiment_preScore.mean()\n"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["regiment\n","Dragoons      15.50\n","Nighthawks    15.25\n","Scouts         2.50\n","Name: preTestScore, dtype: float64"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"9_XCQAP5sF5r"},"source":["### <font color=\"green\"> 1.2 Challenges</font>"]},{"cell_type":"code","metadata":{"id":"h_MYzHTPsFWe","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1621163454288,"user_tz":-180,"elapsed":1020,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"d28818e9-c6e0-4543-bf6c-b2ca2138a7e8"},"source":["# Challenge 1\n","# Let us view the following Dataframe upon creation from the following Dictionary\n","#\n","data = {'name': ['Alice', 'Robert', 'Charles', 'David', 'Eric'],\n","        'year of joining': [2014, 2015, 2013, 2014, 2013],\n","        'salary': [40000, 25000, 35000, 200000, 30000]}\n","df = pd.DataFrame(data, index = ['I&M', 'I&M', 'KCB', 'KCB', 'KCB'])\n","df\n","\n","# Let us view salary column\n","\n","df['salary']\n","# We would like to compare the name and the salary columns\n","\n","df[['name','salary']]\n","# Let's view the first three records of the dataframe\n","df[:3]\n","\n","# Which employee(s) earn(s) a salary of more than 30000\n","df[df['salary']>30000]\n","\n","# Which employee(s) earn(s) a salary of less than 30000 and joined before 2015\n","\n","df[(df['salary']  > 30000) & (df['year of joining'] < 2015)]"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year of joining</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>I&amp;M</th>\n","      <td>Alice</td>\n","      <td>2014</td>\n","      <td>40000</td>\n","    </tr>\n","    <tr>\n","      <th>KCB</th>\n","      <td>Charles</td>\n","      <td>2013</td>\n","      <td>35000</td>\n","    </tr>\n","    <tr>\n","      <th>KCB</th>\n","      <td>David</td>\n","      <td>2014</td>\n","      <td>200000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        name  year of joining  salary\n","I&M    Alice             2014   40000\n","KCB  Charles             2013   35000\n","KCB    David             2014  200000"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"SQ-lM05NsOfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621163629966,"user_tz":-180,"elapsed":4401,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"e204f7d2-c25d-4e0d-9593-010470765075"},"source":["# Challenge 2\n","# Find out the person with greatest age from the Dataframe that you will create\n","# upon creating the Dictionary below\n","# \n","\n","# Create a DataFrame\n","df = {'Name':['Audrey','Kwasi','Parul','Lohinee','James','Catherine',\n","'Val','Robert','Alex','Alisa','Murkomen','Judy'],\n","'Age':[26,24,23,22,23,24,26,24,22,23,24,24],\n","'Score':[85,63,55,74,31,77,85,63,42,62,89,77]}\n","\n","df=pd.DataFrame(df)\n","df['Age'].max()"],"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"o1h4cB76sPbm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621164052836,"user_tz":-180,"elapsed":3064,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"807b5a90-6bfb-4fa9-abda-d1fb307d92e0"},"source":["# Challenge 3\n","# Get the unique values of the continent column from the Dataset below\n","url = \"http://bit.ly/FiveYearData\"\n","#\n","df = pd.read_csv(url)\n","df\n","df['continent'].unique()"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Asia', 'Europe', 'Africa', 'Americas', 'Oceania'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"tg4YYl3esQt6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621164056801,"user_tz":-180,"elapsed":1111,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"48387e2d-9fcf-4e4c-e7a7-58e15390687d"},"source":["# Challenge 4\n","# How many countries are there in the dataset on challenge 3\n","# \n","df['country'].count()"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1704"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"aRwUwGONsRr3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621164311844,"user_tz":-180,"elapsed":7319,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"f6baa030-5b61-436e-f948-6c875a72231d"},"source":["# Challenge 5\n","# What is the average number of goals per teams from the dictionary below\n","# \n","\n","# Creating our dataframe\n","football = {'Team':['Arsenal', 'Manchester United', 'Arsenal', \n","                   'Arsenal', 'Chelsea', 'Manchester United', \n","                   'Manchester United', 'Chelsea', 'Chelsea', 'Chelsea'],     \n","           'Player':['Ozil', 'Pogba', 'Lucas', 'Aubameyang', \n","                       'Hazard', 'Mata', 'Lukaku', 'Morata',  \n","                                         'Giroud', 'Kante'],                          \n","           'Goals':[6, 4, 7, 5, 10, 3, 1, 6, 3, 4]} \n","\n","df = pd.DataFrame(football)\n","df\n","df['Goals'].groupby(df['Team']).mean()"],"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Team\n","Arsenal              6.000000\n","Chelsea              5.750000\n","Manchester United    2.666667\n","Name: Goals, dtype: float64"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"C2opvjY3p6zc"},"source":["## 1.3 Selecting and Sorting\n"]},{"cell_type":"code","metadata":{"id":"5zZPvy29p9bE","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621167105846,"user_tz":-180,"elapsed":1234,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"dd9a4bdb-c333-4181-b5d4-b7ed79a97dbb"},"source":["# Example 1\n","# In this section, we will select and sort our dataframes\n","# We will start off by ranking Rows Of Pandas Dataframes as shown \n","#\n","\n","# Creating dataframe\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [4, 24, 31, 2, 3],\n","        'coverage': [25, 94, 57, 62, 70]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n","\n","# Creating a new column that is the rank of the value of coverage in ascending order\n","# Uncomment the line below after running previous lines\n","df['coverageRanked'] = df['coverage'].rank(ascending=1)\n","df"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","      <th>coverage</th>\n","      <th>coverageRanked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cochice</th>\n","      <td>Jason</td>\n","      <td>2012</td>\n","      <td>4</td>\n","      <td>25</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>Pima</th>\n","      <td>Molly</td>\n","      <td>2012</td>\n","      <td>24</td>\n","      <td>94</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>Santa Cruz</th>\n","      <td>Tina</td>\n","      <td>2013</td>\n","      <td>31</td>\n","      <td>57</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>Maricopa</th>\n","      <td>Jake</td>\n","      <td>2014</td>\n","      <td>2</td>\n","      <td>62</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>Yuma</th>\n","      <td>Amy</td>\n","      <td>2014</td>\n","      <td>3</td>\n","      <td>70</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             name  year  reports  coverage  coverageRanked\n","Cochice     Jason  2012        4        25             1.0\n","Pima        Molly  2012       24        94             5.0\n","Santa Cruz   Tina  2013       31        57             2.0\n","Maricopa     Jake  2014        2        62             3.0\n","Yuma          Amy  2014        3        70             4.0"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"vLhFrqNiqWDX","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1621165388805,"user_tz":-180,"elapsed":1058,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"1a1abe71-e5bc-4b48-c7b8-f3dd147fdddf"},"source":["# Example 2\n","# Next, we will Select Rows When Columns that Contain Certain Values\n","# \n","\n","# Create an example dataframe\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [4, 24, 31, 2, 3]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n","\n","# Get rows where column has certain values\n","# Uncomment the line below after running previous lines\n","value_list = ['Tina', 'Molly', 'Jason']\n","df[df.name.isin(value_list)]\n","\n","# Get rows where column doesn't have certain values\n","# Uncomment the line below after running previous lines\n","df[~df.name.isin(value_list)]"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Maricopa</th>\n","      <td>Jake</td>\n","      <td>2014</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Yuma</th>\n","      <td>Amy</td>\n","      <td>2014</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          name  year  reports\n","Maricopa  Jake  2014        2\n","Yuma       Amy  2014        3"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"Q8wjaHL3qV-1","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1621165575266,"user_tz":-180,"elapsed":3490,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"78b5484f-49e1-4733-d720-0c74adf907da"},"source":["# Example 3\n","# Then, Select Rows With A Certain Value\n","\n","# Create an example dataframe\n","data = {'name': ['Jason', 'Molly'], \n","        'country': [['Syria', 'Lebanon'],['Spain', 'Morocco']]}\n","df = pd.DataFrame(data)\n","df\n","\n","# Uncomment the line below after running previous lines\n","df[df['country'].map(lambda country: 'Syria' in country)]\n"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jason</td>\n","      <td>[Syria, Lebanon]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    name           country\n","0  Jason  [Syria, Lebanon]"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"eGiiPkCvqu_W","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1621165674668,"user_tz":-180,"elapsed":2167,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"b7433bc8-70e3-4990-c46c-640ee812435b"},"source":["# Example 4\n","# Select Rows With Multiple Filters\n","#\n","\n","# Create an example dataframe\n","data = {'name': ['A', 'B', 'C', 'D', 'E'], \n","        'score': [1,2,3,4,5]}\n","df = pd.DataFrame(data)\n","df\n","\n","# Select rows of the dataframe where df.score is greater than 1 and less and 5\n","# Uncomment the line below after running previous lines\n","df[(df['score'] > 1) & (df['score'] < 5)]\n"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  name  score\n","1    B      2\n","2    C      3\n","3    D      4"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"qZb_iZhpqZ0T","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1621166082292,"user_tz":-180,"elapsed":1111,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"5a12b69a-2ba7-4395-b822-2626c4b489fc"},"source":["# Example 5\n","# Selecting DataFrame Rows Based On Conditions\n","# \n","\n","# import numpy\n","import numpy as np\n","\n","# Creating a dataframe\n","raw_data = {'first_name': ['Jason', 'Molly', np.nan, np.nan, np.nan], \n","        'nationality': ['USA', 'USA', 'France', 'UK', 'UK'], \n","        'age': [42, 52, 36, 24, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'nationality', 'age'])\n","df\n","\n","# Method 1: Using Boolean Variables\n","# Create variable with TRUE if nationality is USA\n","# Uncomment the line below after running previous lines\n","american = df['nationality'] == \"USA\"\n","american\n","\n","# Create variable with TRUE if age is greater than 50\n","# Uncomment the line below after running previous lines\n","elderly = df['age'] > 50\n","elderly\n","\n","# Select all cases where nationality is USA and age is greater than 50\n","# Uncomment the line below after running previous lines \n","df[american & elderly]\n","\n","\n","# Method 2: Using variable attributes\n","# Select all cases where the first name is not missing and nationality is USA\n","# Uncomment the line below after running previous lines\n","df[df['first_name'].notnull() & (df['nationality'] == \"USA\")]"],"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>nationality</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jason</td>\n","      <td>USA</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Molly</td>\n","      <td>USA</td>\n","      <td>52</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name nationality  age\n","0      Jason         USA   42\n","1      Molly         USA   52"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"id":"7q-WUNwOqxgj","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621166234670,"user_tz":-180,"elapsed":1354,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"e9576965-343a-472d-c600-152cb9a9498f"},"source":["# Example 6\n","# Sorting Rows In pandas Dataframes\n","# \n","\n","# Creating a Dataframe to work with\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [1, 2, 1, 2, 3],\n","        'coverage': [2, 2, 3, 3, 3]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n","\n","# Sort the dataframe’s rows by reports, in descending order\n","# Uncomment the line below after running previous lines\n","df.sort_values(by='reports', ascending=0)\n","\n","# Sort the dataframe’s rows by coverage and then by reports, in ascending order\n","# Uncomment the line below after running previous lines\n","df.sort_values(by=['coverage', 'reports'])\n"],"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","      <th>coverage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cochice</th>\n","      <td>Jason</td>\n","      <td>2012</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Pima</th>\n","      <td>Molly</td>\n","      <td>2012</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Santa Cruz</th>\n","      <td>Tina</td>\n","      <td>2013</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Maricopa</th>\n","      <td>Jake</td>\n","      <td>2014</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Yuma</th>\n","      <td>Amy</td>\n","      <td>2014</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             name  year  reports  coverage\n","Cochice     Jason  2012        1         2\n","Pima        Molly  2012        2         2\n","Santa Cruz   Tina  2013        1         3\n","Maricopa     Jake  2014        2         3\n","Yuma          Amy  2014        3         3"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"markdown","metadata":{"id":"BfpO_aWfsXXQ"},"source":["### <font color=\"green\">1.3 Challenges</font>"]},{"cell_type":"code","metadata":{"id":"EwS81YKwscx6","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1621167263491,"user_tz":-180,"elapsed":1153,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"d694ffaa-f712-47cd-a516-426f1a6305b7"},"source":["# Challenge 1\n","# Create a new column ranking the following cars by price \n","# \n","\n","Cars = {'Brand': ['Honda Civic', 'Toyota Corolla', 'Ford Focus', 'Audi A4'],\n","        'Price': [22000, 25000, 27000, 35000],\n","        'Year': [2015, 2013, 2018, 2018]}\n","df=pd.DataFrame(Cars)\n","df['Price_Rank']=df['Price'].rank(ascending=1)\n","df"],"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Brand</th>\n","      <th>Price</th>\n","      <th>Year</th>\n","      <th>Price_Rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Honda Civic</td>\n","      <td>22000</td>\n","      <td>2015</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Toyota Corolla</td>\n","      <td>25000</td>\n","      <td>2013</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ford Focus</td>\n","      <td>27000</td>\n","      <td>2018</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Audi A4</td>\n","      <td>35000</td>\n","      <td>2018</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Brand  Price  Year  Price_Rank\n","0     Honda Civic  22000  2015         1.0\n","1  Toyota Corolla  25000  2013         2.0\n","2      Ford Focus  27000  2018         3.0\n","3         Audi A4  35000  2018         4.0"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"q4SFJY8Xsd8p","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1621174042427,"user_tz":-180,"elapsed":4458,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"965b13c8-5adb-4720-b6e5-2e55e12e6116"},"source":["# Challenge 2\n","# Let's get the rows when the column contains certain values\n","#\n","\n","data = {'model': ['Lisa', 'Lisa 2', 'Macintosh 128K', 'Macintosh 512K'],\n","        'launched': [1983, 1984, 1984, 1984],\n","        'discontinued': [1986, 1985, 1984, 1986]}\n","columns = ['model', 'launched', 'discontinued']\n","df=pd.DataFrame(data)\n","df\n","# Get the rows where the column model contains Lisa\n","\n","df[df['model']=='Lisa']\n","# Get the rows where the column model does not contain Macintosh 128K\n","#df[~df['model']=='Macintosh 128K']"],"execution_count":193,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>launched</th>\n","      <th>discontinued</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Lisa</td>\n","      <td>1983</td>\n","      <td>1986</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  model  launched  discontinued\n","0  Lisa      1983          1986"]},"metadata":{"tags":[]},"execution_count":193}]},{"cell_type":"code","metadata":{"id":"fUZfz_79sfJO","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1621174086066,"user_tz":-180,"elapsed":1266,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"ce3aee81-0fcd-42c1-f384-fee9c689034e"},"source":["# Challenge 3\n","# Select the rows with the value blue or yellow from the Dataframe below\n","#\n","data = {'name': ['Willam', 'Alex', 'Oliech', 'Julie'],\n","'age': [20, 19, 22, 21],\n","'favorite_color': ['blue', 'blue', 'yellow', \"green\"],\n","'grade': [88, 92, 95, 70]}\n","df=pd.DataFrame(data)\n","df\n","df[(df['favorite_color'] == \"blue\") | (df['favorite_color'] == \"yellow\")]"],"execution_count":195,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>age</th>\n","      <th>favorite_color</th>\n","      <th>grade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Willam</td>\n","      <td>20</td>\n","      <td>blue</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Alex</td>\n","      <td>19</td>\n","      <td>blue</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Oliech</td>\n","      <td>22</td>\n","      <td>yellow</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name  age favorite_color  grade\n","0  Willam   20           blue     88\n","1    Alex   19           blue     92\n","2  Oliech   22         yellow     95"]},"metadata":{"tags":[]},"execution_count":195}]},{"cell_type":"code","metadata":{"id":"OXMrd5EUsgMY","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1621175165123,"user_tz":-180,"elapsed":1235,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"7fedef7c-7380-4d3d-84fd-7288a749c88d"},"source":["# Challenge 4\n","# Using the following dataset, which counties have less than 50,000 households?\n","#url = \"http://bit.ly/KeHouseholds1\"\n","# This dataset shows the distribution of households based on their age group, gender and household head.\n","#\n","df=pd.read_csv(\"/content/Percentage_Distribution_of_Households_by_Age_and_Sex_of_Household_Head.csv\")\n","df\n","df[df['Number_of_households'] < 50000]"],"execution_count":226,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>County</th>\n","      <th>Gender</th>\n","      <th>Age_Group_of_Household_head_15-24_%_</th>\n","      <th>Age_Group_of_Household_head_25-34_%</th>\n","      <th>Age_Group_of_Household_head_35-59_%</th>\n","      <th>Age_Group_of_Household_head_60+_%</th>\n","      <th>Number_of_households</th>\n","      <th>County_Centroid</th>\n","      <th>OBJECTID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Kwale</td>\n","      <td>Female</td>\n","      <td>10.9%</td>\n","      <td>25.4%</td>\n","      <td>46.5%</td>\n","      <td>17.1%</td>\n","      <td>40265</td>\n","      <td>(-4.1398571640000004, 39.15036963)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tana Rriver</td>\n","      <td>Female</td>\n","      <td>16.9%</td>\n","      <td>25.6%</td>\n","      <td>43.3%</td>\n","      <td>14.2%</td>\n","      <td>14447</td>\n","      <td>(-1.557428783, 39.412916930000002)</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Lamu</td>\n","      <td>Female</td>\n","      <td>9.5%</td>\n","      <td>22.6%</td>\n","      <td>48.7%</td>\n","      <td>19.2%</td>\n","      <td>5515</td>\n","      <td>(-2.0391399720000001, 40.767880740000003)</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Taita Taveta</td>\n","      <td>Female</td>\n","      <td>7.3%</td>\n","      <td>19.4%</td>\n","      <td>49.1%</td>\n","      <td>24.1%</td>\n","      <td>23915</td>\n","      <td>(-3.4337677430000002, 38.417085350000001)</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Marsabit</td>\n","      <td>Female</td>\n","      <td>14.9%</td>\n","      <td>22.6%</td>\n","      <td>40.7%</td>\n","      <td>21.7%</td>\n","      <td>21594</td>\n","      <td>(2.9818558570000002, 37.570225430000001)</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Nyandarua</td>\n","      <td>Female</td>\n","      <td>6.8%</td>\n","      <td>21.1%</td>\n","      <td>47.9%</td>\n","      <td>24.2%</td>\n","      <td>49694</td>\n","      <td>(-0.32014949999999998, 36.480091790000003)</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Kirinyaga</td>\n","      <td>Female</td>\n","      <td>6.6%</td>\n","      <td>20.8%</td>\n","      <td>43.4%</td>\n","      <td>29.1%</td>\n","      <td>46190</td>\n","      <td>(-0.522402857, 37.318654029999998)</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Isiolo</td>\n","      <td>Female</td>\n","      <td>16.6%</td>\n","      <td>26%</td>\n","      <td>41.8%</td>\n","      <td>15.6%</td>\n","      <td>12070</td>\n","      <td>(1.011526022, 38.539068929999999)</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Tharaka</td>\n","      <td>Female</td>\n","      <td>7.7%</td>\n","      <td>22.4%</td>\n","      <td>44.6%</td>\n","      <td>25.4%</td>\n","      <td>28325</td>\n","      <td>(-0.19534945200000001, 37.932166090000003)</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Embu</td>\n","      <td>Female</td>\n","      <td>7.4%</td>\n","      <td>21.1%</td>\n","      <td>45.9%</td>\n","      <td>25.6%</td>\n","      <td>43021</td>\n","      <td>(-0.60206859300000004, 37.625252140000001)</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Garissa</td>\n","      <td>Female</td>\n","      <td>10.8%</td>\n","      <td>26.3%</td>\n","      <td>47.6%</td>\n","      <td>15.3%</td>\n","      <td>25015</td>\n","      <td>(-0.48705736100000002, 40.182868569999997)</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Wajir</td>\n","      <td>Female</td>\n","      <td>7.8%</td>\n","      <td>23.9%</td>\n","      <td>51.1%</td>\n","      <td>17.2%</td>\n","      <td>16859</td>\n","      <td>(1.8078659530000001, 40.035683050000003)</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Mandera</td>\n","      <td>Female</td>\n","      <td>6%</td>\n","      <td>24.9%</td>\n","      <td>57%</td>\n","      <td>12.1%</td>\n","      <td>23428</td>\n","      <td>(3.4378074010000002, 40.735090630000002)</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Nyamira</td>\n","      <td>Female</td>\n","      <td>9.7%</td>\n","      <td>23.8%</td>\n","      <td>43.8%</td>\n","      <td>22.7%</td>\n","      <td>43093</td>\n","      <td>(-0.64099632399999995, 34.965002290000001)</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Turkana</td>\n","      <td>Female</td>\n","      <td>7.5%</td>\n","      <td>22.7%</td>\n","      <td>52.1%</td>\n","      <td>17.7%</td>\n","      <td>45571</td>\n","      <td>(3.430630909, 35.426022940000003)</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>West Pokot</td>\n","      <td>Female</td>\n","      <td>13.5%</td>\n","      <td>27.4%</td>\n","      <td>42.6%</td>\n","      <td>16.6%</td>\n","      <td>32411</td>\n","      <td>(1.7226525589999999, 35.245003330000003)</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Samburu</td>\n","      <td>Female</td>\n","      <td>20.5%</td>\n","      <td>25.6%</td>\n","      <td>38.7%</td>\n","      <td>15.2%</td>\n","      <td>22492</td>\n","      <td>(1.3198759849999999, 37.116767690000003)</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Baringo</td>\n","      <td>Female</td>\n","      <td>12%</td>\n","      <td>26.2%</td>\n","      <td>42.8%</td>\n","      <td>18.9%</td>\n","      <td>38778</td>\n","      <td>(0.67326285699999999, 35.943438069999999)</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Elgeyo-Marakwet</td>\n","      <td>Female</td>\n","      <td>8.6%</td>\n","      <td>22.7%</td>\n","      <td>44.8%</td>\n","      <td>23.9%</td>\n","      <td>23967</td>\n","      <td>(0.80064760099999999, 35.536420939999999)</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>Nandi</td>\n","      <td>Female</td>\n","      <td>7.3%</td>\n","      <td>23.1%</td>\n","      <td>47.9%</td>\n","      <td>21.6%</td>\n","      <td>43158</td>\n","      <td>(0.18557890399999999, 35.113956139999999)</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Laikipia</td>\n","      <td>Female</td>\n","      <td>11.6%</td>\n","      <td>24.4%</td>\n","      <td>45.1%</td>\n","      <td>18.9%</td>\n","      <td>37050</td>\n","      <td>(0.32376154499999998, 36.768709860000001)</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Kericho</td>\n","      <td>Female</td>\n","      <td>10.9%</td>\n","      <td>24.5%</td>\n","      <td>45.7%</td>\n","      <td>18.8%</td>\n","      <td>34464</td>\n","      <td>(-0.24299188099999999, 35.336599509999999)</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>Vihiga</td>\n","      <td>Female</td>\n","      <td>6%</td>\n","      <td>17.5%</td>\n","      <td>45.7%</td>\n","      <td>30.7%</td>\n","      <td>49777</td>\n","      <td>(0.078465934000000001, 34.722131930000003)</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Tana Rriver</td>\n","      <td>Male</td>\n","      <td>10.3%</td>\n","      <td>29.2%</td>\n","      <td>47.4%</td>\n","      <td>13.1%</td>\n","      <td>32967</td>\n","      <td>(-1.557428783, 39.412916930000002)</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>Lamu</td>\n","      <td>Male</td>\n","      <td>9.6%</td>\n","      <td>28.7%</td>\n","      <td>47.8%</td>\n","      <td>13.9%</td>\n","      <td>16669</td>\n","      <td>(-2.0391399720000001, 40.767880740000003)</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>Taita Taveta</td>\n","      <td>Male</td>\n","      <td>7.8%</td>\n","      <td>25.6%</td>\n","      <td>49.5%</td>\n","      <td>17.1%</td>\n","      <td>47175</td>\n","      <td>(-3.4337677430000002, 38.417085350000001)</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>Marsabit</td>\n","      <td>Male</td>\n","      <td>5.8%</td>\n","      <td>22.9%</td>\n","      <td>49.9%</td>\n","      <td>21.3%</td>\n","      <td>35347</td>\n","      <td>(2.9818558570000002, 37.570225430000001)</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>Isiolo</td>\n","      <td>Male</td>\n","      <td>9%</td>\n","      <td>27.9%</td>\n","      <td>48.2%</td>\n","      <td>14.8%</td>\n","      <td>19256</td>\n","      <td>(1.011526022, 38.539068929999999)</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>Samburu</td>\n","      <td>Male</td>\n","      <td>9.5%</td>\n","      <td>28.5%</td>\n","      <td>46.4%</td>\n","      <td>15.6%</td>\n","      <td>24862</td>\n","      <td>(1.3198759849999999, 37.116767690000003)</td>\n","      <td>79</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             County  ... OBJECTID\n","1             Kwale  ...        1\n","3       Tana Rriver  ...        3\n","4              Lamu  ...        4\n","5      Taita Taveta  ...        5\n","6          Marsabit  ...        6\n","8         Nyandarua  ...        8\n","10        Kirinyaga  ...       10\n","13           Isiolo  ...       13\n","15          Tharaka  ...       15\n","16             Embu  ...       16\n","20          Garissa  ...       20\n","21            Wajir  ...       21\n","22          Mandera  ...       22\n","29          Nyamira  ...       29\n","30          Turkana  ...       30\n","31       West Pokot  ...       31\n","32          Samburu  ...       32\n","34          Baringo  ...       34\n","36  Elgeyo-Marakwet  ...       36\n","37            Nandi  ...       37\n","38         Laikipia  ...       38\n","42          Kericho  ...       42\n","45           Vihiga  ...       45\n","57      Tana Rriver  ...       57\n","58             Lamu  ...       58\n","59     Taita Taveta  ...       59\n","60         Marsabit  ...       60\n","61           Isiolo  ...       61\n","79          Samburu  ...       79\n","\n","[29 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":226}]},{"cell_type":"code","metadata":{"id":"nUd5qnwashOE","colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"status":"ok","timestamp":1621175283084,"user_tz":-180,"elapsed":6562,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"c0e92547-73a5-4450-faa3-9a938079297b"},"source":["# Challenge 5\n","# Using the following dataset, Which top 3 municipalities have the highest population?\n","#url = 'http://bit.ly/KePopulationDistribution1'\n","# \n","df = pd.read_csv('/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv')\n","df['Total_Population'].max()\n","df.head(3)"],"execution_count":229,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Urban_Center</th>\n","      <th>District</th>\n","      <th>Status</th>\n","      <th>Core-Urban_Male_Population</th>\n","      <th>Core-Urban_Female_Population</th>\n","      <th>Total_Core-Urban_Population</th>\n","      <th>Peri-Urban_Male_Population</th>\n","      <th>Peri-Urban_Female_Population</th>\n","      <th>Total_Peri-Urban_Population</th>\n","      <th>Rural_Male_Population</th>\n","      <th>Rural_Female_Population</th>\n","      <th>Total_Rural_Population</th>\n","      <th>Total_Male_Population</th>\n","      <th>Total_Female_Population</th>\n","      <th>Total_Population</th>\n","      <th>OBJECTID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NAIROBI</td>\n","      <td>Nairobi East/West/North/Westlands</td>\n","      <td>City</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MOMBASA</td>\n","      <td>Mombasa/Kilindini</td>\n","      <td>City</td>\n","      <td>473433</td>\n","      <td>441668</td>\n","      <td>915101</td>\n","      <td>12775.0</td>\n","      <td>10255.0</td>\n","      <td>23030.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>486208</td>\n","      <td>451923</td>\n","      <td>938131</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KISUMU</td>\n","      <td>Kisumu East/West/Nyando</td>\n","      <td>City</td>\n","      <td>131062</td>\n","      <td>128196</td>\n","      <td>259258</td>\n","      <td>62816.0</td>\n","      <td>66237.0</td>\n","      <td>129053.0</td>\n","      <td>10356.0</td>\n","      <td>11261.0</td>\n","      <td>21617.0</td>\n","      <td>204234</td>\n","      <td>205694</td>\n","      <td>409928</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Urban_Center                           District  ... Total_Population  OBJECTID\n","0      NAIROBI  Nairobi East/West/North/Westlands  ...          3133518         0\n","1      MOMBASA                  Mombasa/Kilindini  ...           938131         1\n","2       KISUMU            Kisumu East/West/Nyando  ...           409928         2\n","\n","[3 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":229}]},{"cell_type":"code","metadata":{"id":"d79MaLZ6si_o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175870100,"user_tz":-180,"elapsed":1229,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"baecd385-aaa5-425a-d37b-5fe79d178a4e"},"source":["# Challenge 6\n","# Using the dataset given in challenge 5, sort the rows by the total core urban population \n","#\n","df = pd.read_csv('/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv')\n","df['Total_Core-Urban_Population'].sort_values(ascending=True)"],"execution_count":247,"outputs":[{"output_type":"execute_result","data":{"text/plain":["159       2033\n","28        2070\n","158       2119\n","157       2215\n","156       2319\n","        ...   \n","4       252061\n","2       259258\n","3       286411\n","1       915101\n","0      3133518\n","Name: Total_Core-Urban_Population, Length: 215, dtype: int64"]},"metadata":{"tags":[]},"execution_count":247}]},{"cell_type":"code","metadata":{"id":"5XzRgbIzBJ6d"},"source":["# Challenge 7\n","# Using the following dataset, Which quarter experienced the highest no. of visitors after 2007\n","#url = 'http://bit.ly/VisitorsToKenya'\n","# This dataset comprises of visitor arrivals and departures Between 1991 up to 2014 by the purpose of visiting Kenya\n","# \n","# OUR CODE GOES HERE\n","import pandas as pd\n","\n","tst  = pd.read_csv('http://bit.ly/VisitorsToKenya',delimiter='',)\n","tst.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IwxDABvUp97g"},"source":["## 1.4 Cleaning"]},{"cell_type":"code","metadata":{"id":"4yj3yDXQqbR2","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"ok","timestamp":1621095920655,"user_tz":-180,"elapsed":1890,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"6c4027ed-c4b8-4c4a-82fd-281dbff9113a"},"source":["# Example 1\n","# Assign a new column to a Pandas DataFrame\n","# \n","\n","# Create empty dataframe\n","df = pd.DataFrame() \n","df['name'] = ['John', 'Steve', 'Sarah'] \n","df\n"," \n","# Assign a new column to df called 'age' with a list of ages\n","# Uncomment the line below after running previous lines\n","df.assign(age = [31, 32, 19]) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Steve</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sarah</td>\n","      <td>19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    name  age\n","0   John   31\n","1  Steve   32\n","2  Sarah   19"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"m05L3x9YqbJa","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621095999563,"user_tz":-180,"elapsed":1238,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"f8dba2fb-4423-4ac4-a43b-0d763a678503"},"source":["# Example 2\n","# Lowercase column names in Pandas Dataframe\n","#\n","\n","# Let's first set ipython's max row display\n","pd.set_option('display.max_row', 1000)\n","\n","# Let's first set iPython's max column width to 50\n","pd.set_option('display.max_columns', 50)\n","\n","# Create an example dataframe\n","data = {'NAME': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'YEAR': [2012, 2012, 2013, 2014, 2014], \n","        'REPORTS': [4, 24, 31, 2, 3]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n"," \n","# Map the lowering function to all column names\n","# Uncomment the line below after running previous lines\n","df.columns = map(str.lower, df.columns)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cochice</th>\n","      <td>Jason</td>\n","      <td>2012</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>Pima</th>\n","      <td>Molly</td>\n","      <td>2012</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>Santa Cruz</th>\n","      <td>Tina</td>\n","      <td>2013</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>Maricopa</th>\n","      <td>Jake</td>\n","      <td>2014</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Yuma</th>\n","      <td>Amy</td>\n","      <td>2014</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             name  year  reports\n","Cochice     Jason  2012        4\n","Pima        Molly  2012       24\n","Santa Cruz   Tina  2013       31\n","Maricopa     Jake  2014        2\n","Yuma          Amy  2014        3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"qo5k1y_7qBto","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1621096101237,"user_tz":-180,"elapsed":1091,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"fcf34b9a-39d0-4828-e953-5a87677267aa"},"source":["# Example 3\n","# While doing data analysis, finding duplicates in your data is very important. \n","# Delete duplicates in pandas\n","#\n","\n","\n","# Create dataframe with duplicates\n","raw_data = {'first_name': ['Jason', 'Jason', 'Jason','Tina', 'Jake', 'Amy'], \n","        'last_name': ['Miller', 'Miller', 'Miller','Ali', 'Milner', 'Cooze'], \n","        'age': [42, 42, 1111111, 36, 24, 73], \n","        'preTestScore': [4, 4, 4, 31, 2, 3],\n","        'postTestScore': [25, 25, 25, 57, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Identify which observations are duplicates\n","# Uncomment the line below after running previous lines\n","df.duplicated()\n","\n","# Drop duplicates\n","# Uncomment the line below after running previous lines\n","df.drop_duplicates()\n","\n","# Drop duplicates in a specific column\n","# Uncomment the line below after running previous lines\n","df.drop_duplicates(['first_name'], keep='last')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>preTestScore</th>\n","      <th>postTestScore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Jason</td>\n","      <td>Miller</td>\n","      <td>1111111</td>\n","      <td>4</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tina</td>\n","      <td>Ali</td>\n","      <td>36</td>\n","      <td>31</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Jake</td>\n","      <td>Milner</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Amy</td>\n","      <td>Cooze</td>\n","      <td>73</td>\n","      <td>3</td>\n","      <td>70</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name      age  preTestScore  postTestScore\n","2      Jason    Miller  1111111             4             25\n","3       Tina       Ali       36            31             57\n","4       Jake    Milner       24             2             62\n","5        Amy     Cooze       73             3             70"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"SuVreA2DqCuS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621101014004,"user_tz":-180,"elapsed":4278,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"8dac83d0-2d0b-4b02-bae8-fd4fa996a625"},"source":["# Example 4\n","# Another crucial part of data analysis is finding missing data and deleting them. Let's lookd at how to deal with missing data \n","# Missing data in pandas Dataframes\n","#\n","\n","raw_data = {'first_name': ['Jason', np.nan, 'Tina', 'Jake', 'Amy'], \n","        'last_name': ['Miller', np.nan, 'Ali', 'Milner', 'Cooze'], \n","        'age': [42, np.nan, 36, 24, 73], \n","        'sex': ['m', np.nan, 'f', 'm', 'f'], \n","        'preTestScore': [4, np.nan, np.nan, 2, 3],\n","        'postTestScore': [25, np.nan, np.nan, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'sex', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Checking if there are missing values in your data\n","# Uncomment the line below after running previous lines\n","df.isnull() #returns a boolean value for all the cells that have Nan  value\n","\n","\n","# Drop missing observations\n","# Uncomment the line below after running previous lines\n","df_no_missing = df.dropna()\n","df_no_missing\n","\n","# Drop rows where all cells in that row is NA\n","# Uncomment the line below after running previous lines\n","df_cleaned = df.dropna(how='all')\n","df_cleaned\n","\n","# Drop column if they only contain missing values\n","# Uncomment the line below after running previous lines\n","df.dropna(axis=1, how='all')\n","\n","# Drop rows that contain less than five observations\n","# Uncomment the line below after running previous lines\n","df.dropna(thresh=5)\n","\n","# Fill in missing data with zeros\n","# Uncomment the line below after running previous lines\n","df.fillna(0)\n","\n","# Fill in missing in preTestScore with the mean value of preTestScore\n","# Uncomment the line below after running previous lines\n","df[\"preTestScore\"].fillna(df[\"preTestScore\"].mean(), inplace=True)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>preTestScore</th>\n","      <th>postTestScore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jason</td>\n","      <td>Miller</td>\n","      <td>42.0</td>\n","      <td>m</td>\n","      <td>4.0</td>\n","      <td>25.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tina</td>\n","      <td>Ali</td>\n","      <td>36.0</td>\n","      <td>f</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Jake</td>\n","      <td>Milner</td>\n","      <td>24.0</td>\n","      <td>m</td>\n","      <td>2.0</td>\n","      <td>62.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amy</td>\n","      <td>Cooze</td>\n","      <td>73.0</td>\n","      <td>f</td>\n","      <td>3.0</td>\n","      <td>70.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name   age  sex  preTestScore  postTestScore\n","0      Jason    Miller  42.0    m           4.0           25.0\n","1        NaN       NaN   NaN  NaN           3.0            NaN\n","2       Tina       Ali  36.0    f           3.0            NaN\n","3       Jake    Milner  24.0    m           2.0           62.0\n","4        Amy     Cooze  73.0    f           3.0           70.0"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"U_7vT83gq0TP","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1621101232507,"user_tz":-180,"elapsed":1055,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"a3293b63-bf74-456b-88fc-ca9903e23e04"},"source":["# Example 5\n","# Dropping rows and columns in pandas Dataframe\n","#\n","\n","# Create a dataframe\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'year': [2012, 2012, 2013, 2014, 2014], \n","        'reports': [4, 24, 31, 2, 3]}\n","df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n","df\n","\n","# Drop an observation (row)\n","# Uncomment the line below after running previous lines\n","df.drop(['Cochice', 'Pima'])\n","\n","# Drop a variable (column). \n","# NB: axis=1 denotes that we are referring to a column, not a row\n","# Uncomment the line below after running previous lines\n","df.drop('reports', axis=1)\n","\n","# Drop a row if it contains a certain value (in this case, “Tina”)\n","# Create a new dataframe called df that includes all rows where \n","# the value of a cell in the name column does not equal “Tina”\n","# Uncomment the line below after running previous lines\n","df[df.name != 'Tina']\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>reports</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cochice</th>\n","      <td>Jason</td>\n","      <td>2012</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>Pima</th>\n","      <td>Molly</td>\n","      <td>2012</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>Maricopa</th>\n","      <td>Jake</td>\n","      <td>2014</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Yuma</th>\n","      <td>Amy</td>\n","      <td>2014</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           name  year  reports\n","Cochice   Jason  2012        4\n","Pima      Molly  2012       24\n","Maricopa   Jake  2014        2\n","Yuma        Amy  2014        3"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"66Fjm3xmslG7"},"source":["### <font color=\"green\">1.4 Challenges</font>"]},{"cell_type":"code","metadata":{"id":"RH_6cmIostHA","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1621101722237,"user_tz":-180,"elapsed":1130,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"a80bc83b-4b0e-4975-d6bc-59bc25904856"},"source":["# Challenge 1\n","# Let's assign the new column address to the created dataframe frow the dictionary below\n","#\n","\n","# Define a dictionary containing Students data \n","finals = {'Name': ['Robert', 'Thomas', 'Susan', 'Irene'], \n","        'Height': [5.1, 6.2, 5.1, 5.2], \n","        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']} \n","address = ['UoN', 'Strathmore', 'JKUAT', 'JKUAT'] \n","\n","df=pd.DataFrame(finals)\n","df['address']=address\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Height</th>\n","      <th>Qualification</th>\n","      <th>address</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Robert</td>\n","      <td>5.1</td>\n","      <td>Msc</td>\n","      <td>UoN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Thomas</td>\n","      <td>6.2</td>\n","      <td>MA</td>\n","      <td>Strathmore</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Susan</td>\n","      <td>5.1</td>\n","      <td>Msc</td>\n","      <td>JKUAT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Irene</td>\n","      <td>5.2</td>\n","      <td>Msc</td>\n","      <td>JKUAT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Name  Height Qualification     address\n","0  Robert     5.1           Msc         UoN\n","1  Thomas     6.2            MA  Strathmore\n","2   Susan     5.1           Msc       JKUAT\n","3   Irene     5.2           Msc       JKUAT"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"73tUDU64stqu","colab":{"base_uri":"https://localhost:8080/","height":558},"executionInfo":{"status":"ok","timestamp":1621102985519,"user_tz":-180,"elapsed":1016,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"e1b1ec50-1944-4f09-c82f-61d43e387521"},"source":["# Challenge 2\n","# Let us lowercase the column names in the following dataset\n","# url = http://bit.ly/KePopulationDistribution1\n","#\n","df = pd.read_csv(\"/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv\")\n","df\n","df.columns = map(str.lower, df.columns)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>urban_center</th>\n","      <th>district</th>\n","      <th>status</th>\n","      <th>core-urban_male_population</th>\n","      <th>core-urban_female_population</th>\n","      <th>total_core-urban_population</th>\n","      <th>peri-urban_male_population</th>\n","      <th>peri-urban_female_population</th>\n","      <th>total_peri-urban_population</th>\n","      <th>rural_male_population</th>\n","      <th>rural_female_population</th>\n","      <th>total_rural_population</th>\n","      <th>total_male_population</th>\n","      <th>total_female_population</th>\n","      <th>total_population</th>\n","      <th>objectid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NAIROBI</td>\n","      <td>Nairobi East/West/North/Westlands</td>\n","      <td>City</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MOMBASA</td>\n","      <td>Mombasa/Kilindini</td>\n","      <td>City</td>\n","      <td>473433</td>\n","      <td>441668</td>\n","      <td>915101</td>\n","      <td>12775.0</td>\n","      <td>10255.0</td>\n","      <td>23030.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>486208</td>\n","      <td>451923</td>\n","      <td>938131</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KISUMU</td>\n","      <td>Kisumu East/West/Nyando</td>\n","      <td>City</td>\n","      <td>131062</td>\n","      <td>128196</td>\n","      <td>259258</td>\n","      <td>62816.0</td>\n","      <td>66237.0</td>\n","      <td>129053.0</td>\n","      <td>10356.0</td>\n","      <td>11261.0</td>\n","      <td>21617.0</td>\n","      <td>204234</td>\n","      <td>205694</td>\n","      <td>409928</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NAKURU</td>\n","      <td>Nakuru/Nakuru North</td>\n","      <td>Municipality</td>\n","      <td>145038</td>\n","      <td>141373</td>\n","      <td>286411</td>\n","      <td>10843.0</td>\n","      <td>10736.0</td>\n","      <td>21579.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>155881</td>\n","      <td>152109</td>\n","      <td>307990</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ELDORET</td>\n","      <td>Eldoret East/West/Wareng</td>\n","      <td>Municipality</td>\n","      <td>127808</td>\n","      <td>124253</td>\n","      <td>252061</td>\n","      <td>18788.0</td>\n","      <td>18531.0</td>\n","      <td>37319.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>146596</td>\n","      <td>142784</td>\n","      <td>289380</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>SOTIK</td>\n","      <td>Sotik</td>\n","      <td>Town Council</td>\n","      <td>2734</td>\n","      <td>2486</td>\n","      <td>5220</td>\n","      <td>1603.0</td>\n","      <td>1543.0</td>\n","      <td>3146.0</td>\n","      <td>6897.0</td>\n","      <td>6734.0</td>\n","      <td>13631.0</td>\n","      <td>11234</td>\n","      <td>10763</td>\n","      <td>21997</td>\n","      <td>210</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>PORT VICTORIA</td>\n","      <td>Bunyala</td>\n","      <td>Town Council</td>\n","      <td>3101</td>\n","      <td>3460</td>\n","      <td>6561</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7337.0</td>\n","      <td>7803.0</td>\n","      <td>15140.0</td>\n","      <td>10438</td>\n","      <td>11263</td>\n","      <td>21701</td>\n","      <td>211</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>OTHAYA</td>\n","      <td>Nyeri South</td>\n","      <td>Town Council</td>\n","      <td>2385</td>\n","      <td>2752</td>\n","      <td>5137</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6589.0</td>\n","      <td>7217.0</td>\n","      <td>13806.0</td>\n","      <td>8974</td>\n","      <td>9969</td>\n","      <td>18943</td>\n","      <td>212</td>\n","    </tr>\n","    <tr>\n","      <th>213</th>\n","      <td>KAJIADO</td>\n","      <td>Kajiado Central</td>\n","      <td>Town Council</td>\n","      <td>7458</td>\n","      <td>7173</td>\n","      <td>14631</td>\n","      <td>107.0</td>\n","      <td>122.0</td>\n","      <td>229.0</td>\n","      <td>1718.0</td>\n","      <td>1703.0</td>\n","      <td>3421.0</td>\n","      <td>9283</td>\n","      <td>8998</td>\n","      <td>18281</td>\n","      <td>213</td>\n","    </tr>\n","    <tr>\n","      <th>214</th>\n","      <td>WOTE</td>\n","      <td>Makueni</td>\n","      <td>Town Council</td>\n","      <td>4887</td>\n","      <td>4988</td>\n","      <td>9875</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4887</td>\n","      <td>4988</td>\n","      <td>9875</td>\n","      <td>214</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>215 rows × 16 columns</p>\n","</div>"],"text/plain":["      urban_center  ... objectid\n","0          NAIROBI  ...        0\n","1          MOMBASA  ...        1\n","2           KISUMU  ...        2\n","3           NAKURU  ...        3\n","4          ELDORET  ...        4\n","..             ...  ...      ...\n","210          SOTIK  ...      210\n","211  PORT VICTORIA  ...      211\n","212         OTHAYA  ...      212\n","213        KAJIADO  ...      213\n","214           WOTE  ...      214\n","\n","[215 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"1Q0-ybtZstks","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1621103270267,"user_tz":-180,"elapsed":5501,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"9397d548-1552-4963-c785-68e14ef3c885"},"source":["# Challenge 3\n","# Delete duplicate values from the dictionary below\n","# \n","\n","# First creating the following DataFrame\n","d = {\n","    'Name':['Alice','Brian','Rhoda','Pauline','Julius','Catherine',\n","            'Alice','Brian','Kellen','Alice','Alex','Yvonne'],\n","    'Age':[26,24,23,22,23,24,26,24,22,23,24,24],\n","    'Score':[85,63,55,74,31,77,85,63,42,62,89,77]}\n","\n","df=pd.DataFrame(d)\n","df\n","#df.duplicated()\n","\n","df.drop_duplicates()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Alice</td>\n","      <td>26</td>\n","      <td>85</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Brian</td>\n","      <td>24</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Rhoda</td>\n","      <td>23</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Pauline</td>\n","      <td>22</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Julius</td>\n","      <td>23</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Catherine</td>\n","      <td>24</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Kellen</td>\n","      <td>22</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Alice</td>\n","      <td>23</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Alex</td>\n","      <td>24</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Yvonne</td>\n","      <td>24</td>\n","      <td>77</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Name  Age  Score\n","0       Alice   26     85\n","1       Brian   24     63\n","2       Rhoda   23     55\n","3     Pauline   22     74\n","4      Julius   23     31\n","5   Catherine   24     77\n","8      Kellen   22     42\n","9       Alice   23     62\n","10       Alex   24     89\n","11     Yvonne   24     77"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"54xutk3fstfP","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1621104328949,"user_tz":-180,"elapsed":2033,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"68aefe5b-c4a7-4230-f15a-455296c38efa"},"source":["# Challenge 4\n","# Drop the missing columns \n","#\n","\n","# Creating our DataFrame\n","df = {'Name':['George','Andrea','micheal','maggie','Ravi','Xien','Jalpa',np.nan],\n","    'State':['Arizona','Georgia','Newyork','Indiana','Florida','California',np.nan,np.nan],\n","    'Gender':[\"M\",\"F\",\"M\",\"F\",\"M\",\"M\",np.nan,np.nan],      \n","    'Score':[63,48,56,75,np.nan,77,np.nan,np.nan]}\n","df=pd.DataFrame(df)\n","df\n","\n","# Drop all rows that have any NaN (missing) values\n","df.dropna(axis=0, how='all')\n","\n","# Drop records which have more than 2 missing values\n","df_no_missing = df.dropna()\n","df_no_missing\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>State</th>\n","      <th>Gender</th>\n","      <th>Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>George</td>\n","      <td>Arizona</td>\n","      <td>M</td>\n","      <td>63.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Andrea</td>\n","      <td>Georgia</td>\n","      <td>F</td>\n","      <td>48.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>micheal</td>\n","      <td>Newyork</td>\n","      <td>M</td>\n","      <td>56.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>maggie</td>\n","      <td>Indiana</td>\n","      <td>F</td>\n","      <td>75.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Xien</td>\n","      <td>California</td>\n","      <td>M</td>\n","      <td>77.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name       State Gender  Score\n","0   George     Arizona      M   63.0\n","1   Andrea     Georgia      F   48.0\n","2  micheal     Newyork      M   56.0\n","3   maggie     Indiana      F   75.0\n","5     Xien  California      M   77.0"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"J-4ZiKtrsySp","colab":{"base_uri":"https://localhost:8080/","height":558},"executionInfo":{"status":"ok","timestamp":1621104863855,"user_tz":-180,"elapsed":1384,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"4a13b8f6-f6e1-4e30-8e69-e1ab13afab90"},"source":["# Challenge 5\n","# Using the following dataset given, get the records which contain missing observations,\n","# then make a decision which records to delete based on the context.\n","# Act on the decision taken (i.e. Drop/Not dropping) and state your decision below\n","#url = \"http://bit.ly/KePopulationDistribution1\"\n","# \n","df=pd.read_csv(\"/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv\")\n","df\n","df.drop('OBJECTID', axis=1)\n","\n","# Decision Taken:\n","# I decided to drop OBJECTID column because its the same thing with the index .\n","#"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Urban_Center</th>\n","      <th>District</th>\n","      <th>Status</th>\n","      <th>Core-Urban_Male_Population</th>\n","      <th>Core-Urban_Female_Population</th>\n","      <th>Total_Core-Urban_Population</th>\n","      <th>Peri-Urban_Male_Population</th>\n","      <th>Peri-Urban_Female_Population</th>\n","      <th>Total_Peri-Urban_Population</th>\n","      <th>Rural_Male_Population</th>\n","      <th>Rural_Female_Population</th>\n","      <th>Total_Rural_Population</th>\n","      <th>Total_Male_Population</th>\n","      <th>Total_Female_Population</th>\n","      <th>Total_Population</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NAIROBI</td>\n","      <td>Nairobi East/West/North/Westlands</td>\n","      <td>City</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1602104</td>\n","      <td>1531414</td>\n","      <td>3133518</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MOMBASA</td>\n","      <td>Mombasa/Kilindini</td>\n","      <td>City</td>\n","      <td>473433</td>\n","      <td>441668</td>\n","      <td>915101</td>\n","      <td>12775.0</td>\n","      <td>10255.0</td>\n","      <td>23030.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>486208</td>\n","      <td>451923</td>\n","      <td>938131</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KISUMU</td>\n","      <td>Kisumu East/West/Nyando</td>\n","      <td>City</td>\n","      <td>131062</td>\n","      <td>128196</td>\n","      <td>259258</td>\n","      <td>62816.0</td>\n","      <td>66237.0</td>\n","      <td>129053.0</td>\n","      <td>10356.0</td>\n","      <td>11261.0</td>\n","      <td>21617.0</td>\n","      <td>204234</td>\n","      <td>205694</td>\n","      <td>409928</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NAKURU</td>\n","      <td>Nakuru/Nakuru North</td>\n","      <td>Municipality</td>\n","      <td>145038</td>\n","      <td>141373</td>\n","      <td>286411</td>\n","      <td>10843.0</td>\n","      <td>10736.0</td>\n","      <td>21579.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>155881</td>\n","      <td>152109</td>\n","      <td>307990</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ELDORET</td>\n","      <td>Eldoret East/West/Wareng</td>\n","      <td>Municipality</td>\n","      <td>127808</td>\n","      <td>124253</td>\n","      <td>252061</td>\n","      <td>18788.0</td>\n","      <td>18531.0</td>\n","      <td>37319.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>146596</td>\n","      <td>142784</td>\n","      <td>289380</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>SOTIK</td>\n","      <td>Sotik</td>\n","      <td>Town Council</td>\n","      <td>2734</td>\n","      <td>2486</td>\n","      <td>5220</td>\n","      <td>1603.0</td>\n","      <td>1543.0</td>\n","      <td>3146.0</td>\n","      <td>6897.0</td>\n","      <td>6734.0</td>\n","      <td>13631.0</td>\n","      <td>11234</td>\n","      <td>10763</td>\n","      <td>21997</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>PORT VICTORIA</td>\n","      <td>Bunyala</td>\n","      <td>Town Council</td>\n","      <td>3101</td>\n","      <td>3460</td>\n","      <td>6561</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7337.0</td>\n","      <td>7803.0</td>\n","      <td>15140.0</td>\n","      <td>10438</td>\n","      <td>11263</td>\n","      <td>21701</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>OTHAYA</td>\n","      <td>Nyeri South</td>\n","      <td>Town Council</td>\n","      <td>2385</td>\n","      <td>2752</td>\n","      <td>5137</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6589.0</td>\n","      <td>7217.0</td>\n","      <td>13806.0</td>\n","      <td>8974</td>\n","      <td>9969</td>\n","      <td>18943</td>\n","    </tr>\n","    <tr>\n","      <th>213</th>\n","      <td>KAJIADO</td>\n","      <td>Kajiado Central</td>\n","      <td>Town Council</td>\n","      <td>7458</td>\n","      <td>7173</td>\n","      <td>14631</td>\n","      <td>107.0</td>\n","      <td>122.0</td>\n","      <td>229.0</td>\n","      <td>1718.0</td>\n","      <td>1703.0</td>\n","      <td>3421.0</td>\n","      <td>9283</td>\n","      <td>8998</td>\n","      <td>18281</td>\n","    </tr>\n","    <tr>\n","      <th>214</th>\n","      <td>WOTE</td>\n","      <td>Makueni</td>\n","      <td>Town Council</td>\n","      <td>4887</td>\n","      <td>4988</td>\n","      <td>9875</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4887</td>\n","      <td>4988</td>\n","      <td>9875</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>215 rows × 15 columns</p>\n","</div>"],"text/plain":["      Urban_Center  ... Total_Population\n","0          NAIROBI  ...          3133518\n","1          MOMBASA  ...           938131\n","2           KISUMU  ...           409928\n","3           NAKURU  ...           307990\n","4          ELDORET  ...           289380\n","..             ...  ...              ...\n","210          SOTIK  ...            21997\n","211  PORT VICTORIA  ...            21701\n","212         OTHAYA  ...            18943\n","213        KAJIADO  ...            18281\n","214           WOTE  ...             9875\n","\n","[215 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"7jHC3c0jqFHy"},"source":["## 1.5 Analysis"]},{"cell_type":"code","metadata":{"id":"avpOVTs-qIPl","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1621105340492,"user_tz":-180,"elapsed":1040,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"e2a5747e-7a16-43eb-c245-a6673611eec6"},"source":["# Example 1\n","# Descriptive Statistics For pandas Dataframe\n","#\n","\n","data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'age': [42, 52, 36, 24, 73], \n","        'preTestScore': [4, 24, 31, 2, 3],\n","        'postTestScore': [25, 94, 57, 62, 70]}\n","df = pd.DataFrame(data, columns = ['name', 'age', 'preTestScore', 'postTestScore'])\n","df\n","\n","\n","# The sum of all the ages\n","# Uncomment the line below after running previous lines\n","df['age'].sum()\n","\n","# Mean preTestScore\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].mean()\n","\n","# Cumulative sum of preTestScores, moving from the rows from the top\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].cumsum()\n","\n","# Summary statistics on preTestScore\n","# Uncomment the line below after running previous lines.\n","# The output for this summary will be; the total number of rows there is in the column, the mean value for the data in the column, \n","# the standard deviation of the data , min and max values of the data, the 25th 50th 75th percentile of the data.\n","df['preTestScore'].describe()\n","\n","# Count the number of non-NA values\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].count()\n","\n","# Minimum value of preTestScore\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].min()\n","\n","# Maximum value of preTestScore\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].max()\n","\n","# Median value of preTestScore\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].median()\n","\n","# Sample variance of preTestScore values\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].var()\n","\n","# Sample standard deviation of preTestScore values\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].std()\n","\n","# Skewness of preTestScore values\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].skew()\n","\n","# Kurtosis of preTestScore values\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].kurt()\n","\n","# Correlation Matrix Of Values\n","# A correlation matrix is a table showing correlation coefficents of different variables. In other words, it shows how different columns corelate to each other. The coefficients range between -1 and 1.\n","# The closer the values are to -1 indicates that the variables do not correlate while the closer the values are to 1 indicates that the values have a high correlation.\n","# A correlation matrix is very important when we are trying to understand our data as it serves as input for advanced analysis.\n","# Uncomment the line below after running previous lines\n","df.corr()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>preTestScore</th>\n","      <th>postTestScore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>age</th>\n","      <td>1.000000</td>\n","      <td>-0.105651</td>\n","      <td>0.328852</td>\n","    </tr>\n","    <tr>\n","      <th>preTestScore</th>\n","      <td>-0.105651</td>\n","      <td>1.000000</td>\n","      <td>0.378039</td>\n","    </tr>\n","    <tr>\n","      <th>postTestScore</th>\n","      <td>0.328852</td>\n","      <td>0.378039</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    age  preTestScore  postTestScore\n","age            1.000000     -0.105651       0.328852\n","preTestScore  -0.105651      1.000000       0.378039\n","postTestScore  0.328852      0.378039       1.000000"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"p7rE9W05qIGH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621105592005,"user_tz":-180,"elapsed":6258,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"8845f27a-3709-4b25-9f20-4666b85bc3ec"},"source":["# Example 2\n","# Apply Operations To Groups In Pandas\n","#\n","\n","# Create dataframe\n","raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n","        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n","        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n","        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n","        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Create a groupby variable that groups preTestScores by regiment\n","# Uncomment the line below after running previous lines\n","groupby_regiment = df['preTestScore'].groupby(df['regiment'])\n","groupby_regiment\n","\n","# Descriptive statistics by group\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].groupby(df['regiment']).describe()\n","\n","# Mean of each regiment’s preTestScore\n","# Uncomment the line below after running previous lines\n","groupby_regiment.mean()\n","\n","# Mean preTestScores grouped by regiment and company\n","# Uncomment the line below after running previous lines\n","df['preTestScore'].groupby([df['regiment'], df['company']]).mean()\n","\n","# Number of observations in each regiment and company\n","# Uncomment the line below after running previous lines\n","df.groupby(['regiment', 'company']).size()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["regiment    company\n","Dragoons    1st        2\n","            2nd        2\n","Nighthawks  1st        2\n","            2nd        2\n","Scouts      1st        2\n","            2nd        2\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"LmExhKs_qjNX","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1621105674613,"user_tz":-180,"elapsed":1446,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"763a4f40-6450-411e-ab3b-947c8aa5e42b"},"source":["# Example 3\n","# Random Sampling Dataframe\n","# \n","\n","raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n","        'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n","        'age': [42, 52, 36, 24, 73], \n","        'preTestScore': [4, 24, 31, 2, 3],\n","        'postTestScore': [25, 94, 57, 62, 70]}\n","df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n","df\n","\n","# Select a random subset of 2 without replacement\n","# Uncomment the line below after running previous lines\n","df.take(np.random.permutation(len(df))[:2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>age</th>\n","      <th>preTestScore</th>\n","      <th>postTestScore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jason</td>\n","      <td>Miller</td>\n","      <td>42</td>\n","      <td>4</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Molly</td>\n","      <td>Jacobson</td>\n","      <td>52</td>\n","      <td>24</td>\n","      <td>94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  age  preTestScore  postTestScore\n","0      Jason    Miller   42             4             25\n","1      Molly  Jacobson   52            24             94"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"iHg3qJbYq4iY","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1621105866212,"user_tz":-180,"elapsed":1216,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"c5419dc0-8533-4462-ffba-dd84c8878e1d"},"source":["# Example 4\n","# Pivot Tables In pandas\n","#\n","\n","# Create dataframe\n","raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n","        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n","        'TestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3]}\n","df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'TestScore'])\n","df\n","\n","# Create a pivot table of group means, by company and regiment\n","# Uncomment the line below after running previous lines\n","pd.pivot_table(df, index=['regiment','company'], aggfunc='mean')\n","\n","# Create a pivot table of group score counts, by company and regiments\n","# Uncomment the line below after running previous lines\n","df.pivot_table(index=['regiment','company'], aggfunc='count')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>TestScore</th>\n","    </tr>\n","    <tr>\n","      <th>regiment</th>\n","      <th>company</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Dragoons</th>\n","      <th>1st</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2nd</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Nighthawks</th>\n","      <th>1st</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2nd</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Scouts</th>\n","      <th>1st</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2nd</th>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    TestScore\n","regiment   company           \n","Dragoons   1st              2\n","           2nd              2\n","Nighthawks 1st              2\n","           2nd              2\n","Scouts     1st              2\n","           2nd              2"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"yOI_UEXDs0XI"},"source":["### <font color=\"green\">1.5 Challenges</font>"]},{"cell_type":"code","metadata":{"id":"lK1ar12Ks7xI","colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"status":"ok","timestamp":1621157025827,"user_tz":-180,"elapsed":1319,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"27486f7a-bc1e-4dca-c465-2682ac0d0ce5"},"source":["# Challenge 1\n","# Using the given dataset, calculate the descriptive statistics of the total population\n","# url = http://bit.ly/KePopulationDistribution1\n","#\n","df= pd.read_csv(\"/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv\")\n","df\n","# The total population in Kenya\n","\n","df['Total_Population'].sum()\n","\n","# The average population per urban center \n","\n","df['Total_Core-Urban_Population'].groupby(df['urdan center']).mean()\n","\n","# The total urban population fo the cities \n","\n","df['Total_Core-Urban_Population'].sum()\n","\n","# Summary statistics on total population\n","\n","df['Total_Population'].describe()\n","\n","# Count the number municipalities in the country\n","\n","df['District'].count()\n","\n","# Which municipality/city/other/town is the most sparcely populated \n","df['District'].min()\n","\n","# Which municipality/city/other/town is the most densely populated \n","df['District'].max()\n","# Median value of the total population \n","\n","df['Total_Population'].median()\n","\n","# Sample variance of the total \n","\n","df['Total_Population'].var()\n","\n","# Sample standard deviation of the total population\n","\n","df['Total_Population'].std()\n","\n","# Correlation of the variables in the given dataset\n","\n","df.corr()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Core-Urban_Male_Population</th>\n","      <th>Core-Urban_Female_Population</th>\n","      <th>Total_Core-Urban_Population</th>\n","      <th>Peri-Urban_Male_Population</th>\n","      <th>Peri-Urban_Female_Population</th>\n","      <th>Total_Peri-Urban_Population</th>\n","      <th>Rural_Male_Population</th>\n","      <th>Rural_Female_Population</th>\n","      <th>Total_Rural_Population</th>\n","      <th>Total_Male_Population</th>\n","      <th>Total_Female_Population</th>\n","      <th>Total_Population</th>\n","      <th>OBJECTID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Core-Urban_Male_Population</th>\n","      <td>1.000000</td>\n","      <td>0.999920</td>\n","      <td>0.999981</td>\n","      <td>0.101339</td>\n","      <td>0.081476</td>\n","      <td>0.091301</td>\n","      <td>-0.064534</td>\n","      <td>-0.066729</td>\n","      <td>-0.065679</td>\n","      <td>0.989407</td>\n","      <td>0.987196</td>\n","      <td>0.988384</td>\n","      <td>-0.218218</td>\n","    </tr>\n","    <tr>\n","      <th>Core-Urban_Female_Population</th>\n","      <td>0.999920</td>\n","      <td>1.000000</td>\n","      <td>0.999979</td>\n","      <td>0.104786</td>\n","      <td>0.085482</td>\n","      <td>0.095033</td>\n","      <td>-0.063030</td>\n","      <td>-0.064926</td>\n","      <td>-0.064022</td>\n","      <td>0.989589</td>\n","      <td>0.987582</td>\n","      <td>0.988666</td>\n","      <td>-0.219914</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Core-Urban_Population</th>\n","      <td>0.999981</td>\n","      <td>0.999979</td>\n","      <td>1.000000</td>\n","      <td>0.103032</td>\n","      <td>0.083437</td>\n","      <td>0.093130</td>\n","      <td>-0.063820</td>\n","      <td>-0.065867</td>\n","      <td>-0.064890</td>\n","      <td>0.989516</td>\n","      <td>0.987404</td>\n","      <td>0.988541</td>\n","      <td>-0.219051</td>\n","    </tr>\n","    <tr>\n","      <th>Peri-Urban_Male_Population</th>\n","      <td>0.101339</td>\n","      <td>0.104786</td>\n","      <td>0.103032</td>\n","      <td>1.000000</td>\n","      <td>0.998079</td>\n","      <td>0.999505</td>\n","      <td>-0.080525</td>\n","      <td>-0.069140</td>\n","      <td>-0.074823</td>\n","      <td>0.363638</td>\n","      <td>0.389059</td>\n","      <td>0.376184</td>\n","      <td>-0.168857</td>\n","    </tr>\n","    <tr>\n","      <th>Peri-Urban_Female_Population</th>\n","      <td>0.081476</td>\n","      <td>0.085482</td>\n","      <td>0.083437</td>\n","      <td>0.998079</td>\n","      <td>1.000000</td>\n","      <td>0.999534</td>\n","      <td>-0.076182</td>\n","      <td>-0.063449</td>\n","      <td>-0.069796</td>\n","      <td>0.345316</td>\n","      <td>0.372721</td>\n","      <td>0.358823</td>\n","      <td>-0.155800</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Peri-Urban_Population</th>\n","      <td>0.091301</td>\n","      <td>0.095033</td>\n","      <td>0.093130</td>\n","      <td>0.999505</td>\n","      <td>0.999534</td>\n","      <td>1.000000</td>\n","      <td>-0.078364</td>\n","      <td>-0.066287</td>\n","      <td>-0.072311</td>\n","      <td>0.354508</td>\n","      <td>0.380949</td>\n","      <td>0.367548</td>\n","      <td>-0.162308</td>\n","    </tr>\n","    <tr>\n","      <th>Rural_Male_Population</th>\n","      <td>-0.064534</td>\n","      <td>-0.063030</td>\n","      <td>-0.063820</td>\n","      <td>-0.080525</td>\n","      <td>-0.076182</td>\n","      <td>-0.078364</td>\n","      <td>1.000000</td>\n","      <td>0.998366</td>\n","      <td>0.999576</td>\n","      <td>0.403351</td>\n","      <td>0.420040</td>\n","      <td>0.411993</td>\n","      <td>0.038775</td>\n","    </tr>\n","    <tr>\n","      <th>Rural_Female_Population</th>\n","      <td>-0.066729</td>\n","      <td>-0.064926</td>\n","      <td>-0.065867</td>\n","      <td>-0.069140</td>\n","      <td>-0.063449</td>\n","      <td>-0.066287</td>\n","      <td>0.998366</td>\n","      <td>1.000000</td>\n","      <td>0.999607</td>\n","      <td>0.402755</td>\n","      <td>0.421647</td>\n","      <td>0.412503</td>\n","      <td>0.045349</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Rural_Population</th>\n","      <td>-0.065679</td>\n","      <td>-0.064022</td>\n","      <td>-0.064890</td>\n","      <td>-0.074823</td>\n","      <td>-0.069796</td>\n","      <td>-0.072311</td>\n","      <td>0.999576</td>\n","      <td>0.999607</td>\n","      <td>1.000000</td>\n","      <td>0.403212</td>\n","      <td>0.421031</td>\n","      <td>0.412421</td>\n","      <td>0.042142</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Male_Population</th>\n","      <td>0.989407</td>\n","      <td>0.989589</td>\n","      <td>0.989516</td>\n","      <td>0.363638</td>\n","      <td>0.345316</td>\n","      <td>0.354508</td>\n","      <td>0.403351</td>\n","      <td>0.402755</td>\n","      <td>0.403212</td>\n","      <td>1.000000</td>\n","      <td>0.999766</td>\n","      <td>0.999944</td>\n","      <td>-0.227123</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Female_Population</th>\n","      <td>0.987196</td>\n","      <td>0.987582</td>\n","      <td>0.987404</td>\n","      <td>0.389059</td>\n","      <td>0.372721</td>\n","      <td>0.380949</td>\n","      <td>0.420040</td>\n","      <td>0.421647</td>\n","      <td>0.421031</td>\n","      <td>0.999766</td>\n","      <td>1.000000</td>\n","      <td>0.999939</td>\n","      <td>-0.227586</td>\n","    </tr>\n","    <tr>\n","      <th>Total_Population</th>\n","      <td>0.988384</td>\n","      <td>0.988666</td>\n","      <td>0.988541</td>\n","      <td>0.376184</td>\n","      <td>0.358823</td>\n","      <td>0.367548</td>\n","      <td>0.411993</td>\n","      <td>0.412503</td>\n","      <td>0.412421</td>\n","      <td>0.999944</td>\n","      <td>0.999939</td>\n","      <td>1.000000</td>\n","      <td>-0.227363</td>\n","    </tr>\n","    <tr>\n","      <th>OBJECTID</th>\n","      <td>-0.218218</td>\n","      <td>-0.219914</td>\n","      <td>-0.219051</td>\n","      <td>-0.168857</td>\n","      <td>-0.155800</td>\n","      <td>-0.162308</td>\n","      <td>0.038775</td>\n","      <td>0.045349</td>\n","      <td>0.042142</td>\n","      <td>-0.227123</td>\n","      <td>-0.227586</td>\n","      <td>-0.227363</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              Core-Urban_Male_Population  ...  OBJECTID\n","Core-Urban_Male_Population                      1.000000  ... -0.218218\n","Core-Urban_Female_Population                    0.999920  ... -0.219914\n","Total_Core-Urban_Population                     0.999981  ... -0.219051\n","Peri-Urban_Male_Population                      0.101339  ... -0.168857\n","Peri-Urban_Female_Population                    0.081476  ... -0.155800\n","Total_Peri-Urban_Population                     0.091301  ... -0.162308\n","Rural_Male_Population                          -0.064534  ...  0.038775\n","Rural_Female_Population                        -0.066729  ...  0.045349\n","Total_Rural_Population                         -0.065679  ...  0.042142\n","Total_Male_Population                           0.989407  ... -0.227123\n","Total_Female_Population                         0.987196  ... -0.227586\n","Total_Population                                0.988384  ... -0.227363\n","OBJECTID                                       -0.218218  ...  1.000000\n","\n","[13 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"C8WhwyH2s9VI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621157541771,"user_tz":-180,"elapsed":1366,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"ae77cb53-0a86-492d-dc32-e2acad9567ca"},"source":["# Challenge 2\n","# Using the given dictionary below, find out the mean and median of the points during the Years\n","# \n","\n","kenyan_premier_league = {'Team': ['Gor Mahia', 'AFC', 'Mathare', 'Ushuru', 'Kariobangi Sharks',\n","   'Tusker', 'Bandari', 'Mumias', 'Thika Utd', 'Kakamega', 'Nakuru Utd', 'Kibera Utd'], \n","   'Year': [2018, 2019, 2017, 2019, 2017, 2019, 2016, 2017, 2016, 2018, 2019, 2017],\n","   'Points':[87, 78, 86, 67, 74, 81, 75, 78, 69, 70, 80, 69]}\n","\n","df=pd.DataFrame(kenyan_premier_league)\n","df\n","df['Points'].mean()\n","df['Points'].median()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["76.5"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-RqruGXas-pK","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1621157942892,"user_tz":-180,"elapsed":1198,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"b6244b77-0698-42eb-a426-3c2f3b905c41"},"source":["# Challenge 3\n","# Randomly select a municipality without replacement from the following dataset\n","# url = http://bit.ly/KePopulationDistribution1\n","# \n","df= pd.read_csv(\"/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv\")\n","df.take(np.random.permutation(len(\"Status\"))[:1])"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Urban_Center</th>\n","      <th>District</th>\n","      <th>Status</th>\n","      <th>Core-Urban_Male_Population</th>\n","      <th>Core-Urban_Female_Population</th>\n","      <th>Total_Core-Urban_Population</th>\n","      <th>Peri-Urban_Male_Population</th>\n","      <th>Peri-Urban_Female_Population</th>\n","      <th>Total_Peri-Urban_Population</th>\n","      <th>Rural_Male_Population</th>\n","      <th>Rural_Female_Population</th>\n","      <th>Total_Rural_Population</th>\n","      <th>Total_Male_Population</th>\n","      <th>Total_Female_Population</th>\n","      <th>Total_Population</th>\n","      <th>OBJECTID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>KEHANCHA</td>\n","      <td>Kuria East/West</td>\n","      <td>Municipality</td>\n","      <td>15143</td>\n","      <td>14966</td>\n","      <td>30109</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>110795.0</td>\n","      <td>115182.0</td>\n","      <td>225977.0</td>\n","      <td>125938</td>\n","      <td>130148</td>\n","      <td>256086</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Urban_Center         District  ... Total_Population  OBJECTID\n","5     KEHANCHA  Kuria East/West  ...           256086         5\n","\n","[1 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"CSmCEJ2etAjt","colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"status":"ok","timestamp":1621158080213,"user_tz":-180,"elapsed":2681,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"ac1f5b88-2700-4133-eec6-36069da21f4d"},"source":["# Challenge 4\n","# From the given dataset, create a pivot table of sum total population by District \n","#\n","df= pd.read_csv(\"/content/Population_Distribution_by_Sex_in_Urban_Centres_and_Status_of_Centre__2009.csv\")\n","pd.pivot_table(df, index=['District','Total_Population'], aggfunc='sum')"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Core-Urban_Female_Population</th>\n","      <th>Core-Urban_Male_Population</th>\n","      <th>OBJECTID</th>\n","      <th>Peri-Urban_Female_Population</th>\n","      <th>Peri-Urban_Male_Population</th>\n","      <th>Rural_Female_Population</th>\n","      <th>Rural_Male_Population</th>\n","      <th>Total_Core-Urban_Population</th>\n","      <th>Total_Female_Population</th>\n","      <th>Total_Male_Population</th>\n","      <th>Total_Peri-Urban_Population</th>\n","      <th>Total_Rural_Population</th>\n","    </tr>\n","    <tr>\n","      <th>District</th>\n","      <th>Total_Population</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Baringo</th>\n","      <th>7160</th>\n","      <td>3358</td>\n","      <td>3303</td>\n","      <td>97</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>245.0</td>\n","      <td>254.0</td>\n","      <td>6661</td>\n","      <td>3603</td>\n","      <td>3557</td>\n","      <td>0.0</td>\n","      <td>499.0</td>\n","    </tr>\n","    <tr>\n","      <th>Baringo Central</th>\n","      <th>27278</th>\n","      <td>9427</td>\n","      <td>8218</td>\n","      <td>42</td>\n","      <td>4044.0</td>\n","      <td>3657.0</td>\n","      <td>994.0</td>\n","      <td>938.0</td>\n","      <td>17645</td>\n","      <td>14465</td>\n","      <td>12813</td>\n","      <td>7701.0</td>\n","      <td>1932.0</td>\n","    </tr>\n","    <tr>\n","      <th>Bomet/Sotik</th>\n","      <th>110963</th>\n","      <td>3400</td>\n","      <td>3635</td>\n","      <td>16</td>\n","      <td>38672.0</td>\n","      <td>38022.0</td>\n","      <td>13801.0</td>\n","      <td>13433.0</td>\n","      <td>7035</td>\n","      <td>55873</td>\n","      <td>55090</td>\n","      <td>76694.0</td>\n","      <td>27234.0</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Bondo</th>\n","      <th>15935</th>\n","      <td>4963</td>\n","      <td>4867</td>\n","      <td>69</td>\n","      <td>140.0</td>\n","      <td>128.0</td>\n","      <td>3012.0</td>\n","      <td>2825.0</td>\n","      <td>9830</td>\n","      <td>8115</td>\n","      <td>7820</td>\n","      <td>268.0</td>\n","      <td>5837.0</td>\n","    </tr>\n","    <tr>\n","      <th>39224</th>\n","      <td>7690</td>\n","      <td>7055</td>\n","      <td>195</td>\n","      <td>9789.0</td>\n","      <td>8934.0</td>\n","      <td>3011.0</td>\n","      <td>2745.0</td>\n","      <td>14745</td>\n","      <td>20490</td>\n","      <td>18734</td>\n","      <td>18723.0</td>\n","      <td>5756.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Vihiga</th>\n","      <th>118696</th>\n","      <td>18790</td>\n","      <td>17608</td>\n","      <td>14</td>\n","      <td>43099.0</td>\n","      <td>39199.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>36398</td>\n","      <td>61889</td>\n","      <td>56807</td>\n","      <td>82298.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Wajir East*</th>\n","      <th>82800</th>\n","      <td>7697</td>\n","      <td>9141</td>\n","      <td>46</td>\n","      <td>31419.0</td>\n","      <td>34543.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16838</td>\n","      <td>39116</td>\n","      <td>43684</td>\n","      <td>65962.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Wajir South/West*</th>\n","      <th>8500</th>\n","      <td>3906</td>\n","      <td>4594</td>\n","      <td>89</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8500</td>\n","      <td>3906</td>\n","      <td>4594</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>West Pokot</th>\n","      <th>71477</th>\n","      <td>10475</td>\n","      <td>10405</td>\n","      <td>175</td>\n","      <td>6695.0</td>\n","      <td>6471.0</td>\n","      <td>18703.0</td>\n","      <td>18728.0</td>\n","      <td>20880</td>\n","      <td>35873</td>\n","      <td>35604</td>\n","      <td>13166.0</td>\n","      <td>37431.0</td>\n","    </tr>\n","    <tr>\n","      <th>Yatta</th>\n","      <th>53144</th>\n","      <td>5458</td>\n","      <td>5346</td>\n","      <td>186</td>\n","      <td>20309.0</td>\n","      <td>19637.0</td>\n","      <td>1204.0</td>\n","      <td>1190.0</td>\n","      <td>10804</td>\n","      <td>26971</td>\n","      <td>26173</td>\n","      <td>39946.0</td>\n","      <td>2394.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>215 rows × 12 columns</p>\n","</div>"],"text/plain":["                                    Core-Urban_Female_Population  ...  Total_Rural_Population\n","District          Total_Population                                ...                        \n","Baringo           7160                                      3358  ...                   499.0\n","Baringo Central   27278                                     9427  ...                  1932.0\n","Bomet/Sotik       110963                                    3400  ...                 27234.0\n","Bondo             15935                                     4963  ...                  5837.0\n","                  39224                                     7690  ...                  5756.0\n","...                                                          ...  ...                     ...\n","Vihiga            118696                                   18790  ...                     0.0\n","Wajir East*       82800                                     7697  ...                     0.0\n","Wajir South/West* 8500                                      3906  ...                     0.0\n","West Pokot        71477                                    10475  ...                 37431.0\n","Yatta             53144                                     5458  ...                  2394.0\n","\n","[215 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":18}]}]}