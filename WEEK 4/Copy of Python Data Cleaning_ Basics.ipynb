{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Python Data Cleaning: Basics","provenance":[{"file_id":"1ypMRSXv1jJalWnOim0DsrhGuMqPc9R5O","timestamp":1621332038968},{"file_id":"1aG7gKTWqLmKVMzviw3SgonVbXz5dHxTz","timestamp":1562533027379}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zERjtLoSL1js"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"pZLONleTl2Ky"},"source":["# Python Data Cleaning: Basics"]},{"cell_type":"markdown","metadata":{"id":"tMorzwEdMnhX"},"source":["## Step 1: Finding and counting missing data\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zCgWU_ioNjBT"},"source":["Having known how missing values in a dataset are created, we will now get introduced to how we can work with such a dataset. The first step that we will perform is to find the missing values and know how many they are. \n","\n"]},{"cell_type":"code","metadata":{"id":"gpIzM0fdLA7b","colab":{"base_uri":"https://localhost:8080/","height":796},"executionInfo":{"status":"ok","timestamp":1621359929365,"user_tz":-180,"elapsed":1692,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"22ee2678-5769-4444-c9c7-524e8195adb7"},"source":["# We will first import our dataset that we will use for the examples. We will do this by first\n","# Importing our pandas library \n","import pandas as pd\n","\n","\n","# then storing the url location of our dataset to the variable url\n","url = 'http://bit.ly/TitanicDataset1'\n","\n","# We will read the dataset from above url and store the dataframe in the variable df\n","df = pd.read_csv(url)\n","df"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allen, Miss. Elisabeth Walton</td>\n","      <td>female</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24160</td>\n","      <td>211.3375</td>\n","      <td>B5</td>\n","      <td>S</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>St Louis, MO</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allison, Master. Hudson Trevor</td>\n","      <td>male</td>\n","      <td>0.9167</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Miss. Helen Loraine</td>\n","      <td>female</td>\n","      <td>2.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mr. Hudson Joshua Creighton</td>\n","      <td>male</td>\n","      <td>30.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>NaN</td>\n","      <td>135.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n","      <td>female</td>\n","      <td>25.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1305</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zabour, Miss. Thamine</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2665</td>\n","      <td>14.4542</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zakarian, Mr. Mapriededer</td>\n","      <td>male</td>\n","      <td>26.5000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2656</td>\n","      <td>7.2250</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","      <td>NaN</td>\n","      <td>304.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zakarian, Mr. Ortin</td>\n","      <td>male</td>\n","      <td>27.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2670</td>\n","      <td>7.2250</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zimmerman, Mr. Leo</td>\n","      <td>male</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>315082</td>\n","      <td>7.8750</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1310 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["      pclass  survived  ...   body                        home.dest\n","0        1.0       1.0  ...    NaN                     St Louis, MO\n","1        1.0       1.0  ...    NaN  Montreal, PQ / Chesterville, ON\n","2        1.0       0.0  ...    NaN  Montreal, PQ / Chesterville, ON\n","3        1.0       0.0  ...  135.0  Montreal, PQ / Chesterville, ON\n","4        1.0       0.0  ...    NaN  Montreal, PQ / Chesterville, ON\n","...      ...       ...  ...    ...                              ...\n","1305     3.0       0.0  ...    NaN                              NaN\n","1306     3.0       0.0  ...  304.0                              NaN\n","1307     3.0       0.0  ...    NaN                              NaN\n","1308     3.0       0.0  ...    NaN                              NaN\n","1309     NaN       NaN  ...    NaN                              NaN\n","\n","[1310 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"2z2oonHgg6gd","colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"status":"ok","timestamp":1621359930143,"user_tz":-180,"elapsed":2446,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"9cd0322e-1ecd-478e-edee-fdcbb1cc7ace"},"source":["# Challenge 1\n","# In parallel to this, we will also be working with another dataset too. We will use it for practice.\n","\n","# Let's first store our url location just like we did above\n","gov_dataset = 'http://bit.ly/GovProjectFinanceDataset1'\n","\n","# Then read the dataset from url and store it in our variable of choice\n","# \n","gov_dataset= pd.read_csv(gov_dataset)\n","\n","\n","# And familiarize ourselves with the dataframe by viewing its first 5 rows\n","# \n","gov_dataset.head(10)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Implementing_Agency</th>\n","      <th>Total_-_GOK_Budget_Est_KES</th>\n","      <th>Total_-_Loan_Budget_Est_KES</th>\n","      <th>Total_-_Grant_Budget_Est_KES</th>\n","      <th>Total_Budget_Supported__by_Donors_KES</th>\n","      <th>Total_2013/2014_Budget_KES</th>\n","      <th>OBJECTID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>0.000000e+00</td>\n","      <td>0</td>\n","      <td>3524395000</td>\n","      <td>3524395000</td>\n","      <td>3524395000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MOEW&amp;NR  National Environment Management Auth...</td>\n","      <td>0.000000e+00</td>\n","      <td>0</td>\n","      <td>300000000</td>\n","      <td>300000000</td>\n","      <td>300000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ministry of Agriculture, Livestock and Fisheries</td>\n","      <td>2.306364e+09</td>\n","      <td>23354779585</td>\n","      <td>8732081258</td>\n","      <td>32086860843</td>\n","      <td>34393225231</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The Presidency</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>MOAL&amp;F  Kenya  Plant Health Inspectorate Serv...</td>\n","      <td>0.000000e+00</td>\n","      <td>0</td>\n","      <td>66916163</td>\n","      <td>66916163</td>\n","      <td>66916163</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ministry of Foreign Affairs</td>\n","      <td>0.000000e+00</td>\n","      <td>0</td>\n","      <td>46000000</td>\n","      <td>46000000</td>\n","      <td>46000000</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>MRDA  Ewaso Ngiro North Dev. Authority (ENNDA)</td>\n","      <td>6.560292e+09</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6560292000</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>MOE&amp;P  Kenya Electricity Transmission Company...</td>\n","      <td>0.000000e+00</td>\n","      <td>1304000000</td>\n","      <td>0</td>\n","      <td>1304000000</td>\n","      <td>1304000000</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Office of The Attorney General and Department...</td>\n","      <td>0.000000e+00</td>\n","      <td>0</td>\n","      <td>1351905890</td>\n","      <td>1351905890</td>\n","      <td>1351905890</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>State Department of Infrastructure</td>\n","      <td>1.227000e+07</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12270000</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 Implementing_Agency  ...  OBJECTID\n","0                                                NaN  ...         0\n","1   MOEW&NR  National Environment Management Auth...  ...         1\n","2   Ministry of Agriculture, Livestock and Fisheries  ...         2\n","3                                     The Presidency  ...         3\n","4   MOAL&F  Kenya  Plant Health Inspectorate Serv...  ...         4\n","5                        Ministry of Foreign Affairs  ...         5\n","6     MRDA  Ewaso Ngiro North Dev. Authority (ENNDA)  ...         6\n","7   MOE&P  Kenya Electricity Transmission Company...  ...         7\n","8   Office of The Attorney General and Department...  ...         8\n","9                 State Department of Infrastructure  ...         9\n","\n","[10 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"nHVATaZXNOO9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359930145,"user_tz":-180,"elapsed":2438,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"246a1a71-744d-4e15-b0d3-905211933877"},"source":["# We count the number of non - missing values in the df dataframe\n","#\n","df.count()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pclass       1309\n","survived     1309\n","name         1309\n","sex          1309\n","age          1046\n","sibsp        1309\n","parch        1309\n","ticket       1309\n","fare         1308\n","cabin         295\n","embarked     1307\n","boat          486\n","body          121\n","home.dest     745\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"RMfbpsNXhSkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931450,"user_tz":-180,"elapsed":3725,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"891fcea8-7c55-4ab6-85ea-07802439d5bb"},"source":["# Challenge 2: Government Project Dataset\n","# We also count the number of non - missing values in the our government project dataset\n","# \n","gov_dataset.count()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Implementing_Agency                      39\n","Total_-_GOK_Budget_Est_KES               39\n","Total_-_Loan_Budget_Est_KES              40\n","Total_-_Grant_Budget_Est_KES             40\n","Total_Budget_Supported__by_Donors_KES    40\n","Total_2013/2014_Budget_KES               40\n","OBJECTID                                 40\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"wsXs2IHFNnNa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931452,"user_tz":-180,"elapsed":3715,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"2dd4c371-282b-426f-e7bb-bf3a00bab5d7"},"source":["# A longer method can be to subtract the no. of non-missing rows from the total number \n","# of rows in the dataframe in order to determine the no. of missing values as shown\n","# \n","num_rows = df.shape[0]\n","num_missing1 = num_rows - df.count() \n","num_missing1"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pclass          1\n","survived        1\n","name            1\n","sex             1\n","age           264\n","sibsp           1\n","parch           1\n","ticket          1\n","fare            2\n","cabin        1015\n","embarked        3\n","boat          824\n","body         1189\n","home.dest     565\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"9TLCUeubhiAF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931460,"user_tz":-180,"elapsed":3713,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"54fcd6e7-ead9-4f89-d5a9-c4ce7429a93c"},"source":["# Challenge 3: Government Project Dataset\n","# We now also subtract the no. of non-missing rows from the total number of rows \n","# to determine the no. of missing values in our government project dataset\n","#\n","num_rows = gov_dataset.shape[0]\n","num_missing2 = num_rows - gov_dataset.count() \n","num_missing2"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Implementing_Agency                      1\n","Total_-_GOK_Budget_Est_KES               1\n","Total_-_Loan_Budget_Est_KES              0\n","Total_-_Grant_Budget_Est_KES             0\n","Total_Budget_Supported__by_Donors_KES    0\n","Total_2013/2014_Budget_KES               0\n","OBJECTID                                 0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"XbjpjZs2ONOU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931461,"user_tz":-180,"elapsed":3702,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"98eb1f2c-6583-4d8f-e0df-4516e703a244"},"source":["# Another method would also be to count the number of missing values in our dataframe,  \n","# using the count_nonzero function from numpy - and including the isnull() method.\n","\n","# But before we do that, we would need import numpy,\n","# \n","import numpy as np\n","\n","# Then count those missing values in our dataframe\n","#\n","np.count_nonzero(df.isnull())"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3869"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"xVsRCHychzr2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931466,"user_tz":-180,"elapsed":3692,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"0c3132bb-1d88-4344-dd7a-c62eccb03d49"},"source":["# Challenge 4: Government Project Dataset\n","# Let's just do what we did in our previous cell. We found out the number of missing values \n","# in our dataset using the count_nonzero function from numpy \n","#\n","np.count_nonzero(gov_dataset.isnull())"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"mN8PrJR0Oqry","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931469,"user_tz":-180,"elapsed":3685,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"2f5b3e5b-d5ca-4101-9a30-091babc433e7"},"source":["# We could also count the number of missing values for a particular column by specifying \n","# the column by still using the count_nonzero function from numpy \n","# \n","np.count_nonzero(df['body'].isnull())"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1189"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"5gKt_D3KiTfB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931472,"user_tz":-180,"elapsed":3677,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"cf1fe465-a581-410e-8313-ade2c6cda1b6"},"source":["# Challenge 5: Government Project Dataset\n","# And again specify how many non-missing values we have in the column: Total_-_GOK_Budget_Est_KES\t\n","#\n","np.count_nonzero(gov_dataset['Total_-_GOK_Budget_Est_KES'].isnull())"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"sMVIZyM7NAWR"},"source":["## Step 2: Clean Missing Data"]},{"cell_type":"markdown","metadata":{"id":"bf4VF5tiPKfK"},"source":["Now that we have been able to identify our missing values in our datasets, we can deal with them in the following ways."]},{"cell_type":"markdown","metadata":{"id":"-KXUxWLb3wKH"},"source":["### a) We can recode/replace these values\n","Here, we can do this by using the fillna method and recoding/replacing the missing values with another value or other values. In this example, we will recode the missing values to 0."]},{"cell_type":"code","metadata":{"id":"aY13KkxRPQdB","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1621359931481,"user_tz":-180,"elapsed":3668,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"16c435a5-c419-4e0d-cc5f-f5103d97f921"},"source":["# We can recode missing values with 0 by doing the following. \n","# Do note that this will appear as 0.0 in your dataframe.\n","# \n","df_recode = df.fillna(0)\n","\n","# then preview the first 5 rows for the recoded dataframe\n","#\n","df_recode.head(5)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allen, Miss. Elisabeth Walton</td>\n","      <td>female</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24160</td>\n","      <td>211.3375</td>\n","      <td>B5</td>\n","      <td>S</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>St Louis, MO</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allison, Master. Hudson Trevor</td>\n","      <td>male</td>\n","      <td>0.9167</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>0.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Miss. Helen Loraine</td>\n","      <td>female</td>\n","      <td>2.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mr. Hudson Joshua Creighton</td>\n","      <td>male</td>\n","      <td>30.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>135.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n","      <td>female</td>\n","      <td>25.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pclass  survived  ...   body                        home.dest\n","0     1.0       1.0  ...    0.0                     St Louis, MO\n","1     1.0       1.0  ...    0.0  Montreal, PQ / Chesterville, ON\n","2     1.0       0.0  ...    0.0  Montreal, PQ / Chesterville, ON\n","3     1.0       0.0  ...  135.0  Montreal, PQ / Chesterville, ON\n","4     1.0       0.0  ...    0.0  Montreal, PQ / Chesterville, ON\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"B-N_zB18QrHx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931486,"user_tz":-180,"elapsed":3659,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"63375c60-7045-4a0c-b355-13d28cae31a0"},"source":["# After recoding, let's check for non-missing values in the recoded dataframe\n","#\n","np.count_nonzero(df_recode.isnull())"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"bGyp0dbhi1b-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621359931488,"user_tz":-180,"elapsed":3651,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"8fd4e179-e4e2-4b74-f770-ca18e7fe3b29"},"source":["# Challenge 6: Government Project Dataset\n","# Nice! Let's now replace the missing values in our dataset with 0 again \n","# just as in our previous example\n","# \n","df_recode1 = gov_dataset.fillna(0)\n","np.count_nonzero(df_recode1.isnull())"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"QaPXaERdleI1"},"source":["**Challenge 7:** Together with your peer now discuss the cases where you might use the above recoding technique."]},{"cell_type":"markdown","metadata":{"id":"2rizu8-L30Th"},"source":["### b) We can fill forward missing values"]},{"cell_type":"markdown","metadata":{"id":"tHxr0SwnSXOX"},"source":["When data is filled data forward, the last known value is used for the next missing value. The missing values are replaced with the last known/recorded value. Let's see how that works."]},{"cell_type":"code","metadata":{"id":"rkY5ZdmzTLeV","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1621360712949,"user_tz":-180,"elapsed":1204,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"4bfcf6cd-4f0b-4872-fc50-732b2ab9ebd8"},"source":["# First lets preview out df ,and note the missing data in the boat and body columns\n","#\n","df[['boat','body']]"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>boat</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>135.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1305</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>NaN</td>\n","      <td>304.0</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1310 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["     boat   body\n","0       2    NaN\n","1      11    NaN\n","2     NaN    NaN\n","3     NaN  135.0\n","4     NaN    NaN\n","...   ...    ...\n","1305  NaN    NaN\n","1306  NaN  304.0\n","1307  NaN    NaN\n","1308  NaN    NaN\n","1309  NaN    NaN\n","\n","[1310 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"MFpvJFFeSLwc","colab":{"base_uri":"https://localhost:8080/","height":864},"executionInfo":{"status":"ok","timestamp":1621360142787,"user_tz":-180,"elapsed":1384,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}},"outputId":"6a12a6c3-ae31-4a4c-82fa-59be72558acf"},"source":["# And now let's fill forward\n","#\n","df_fill_forward = df.fillna(method='ffill')\n","\n","# Then preview our dataframe and try to understand it\n","#\n","df_fill_forward\n","\n","# Did you notice what happens when the column begins with a missing value? \n","# Discuss this with your peer"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allen, Miss. Elisabeth Walton</td>\n","      <td>female</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24160</td>\n","      <td>211.3375</td>\n","      <td>B5</td>\n","      <td>S</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>St Louis, MO</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>Allison, Master. Hudson Trevor</td>\n","      <td>male</td>\n","      <td>0.9167</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Miss. Helen Loraine</td>\n","      <td>female</td>\n","      <td>2.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mr. Hudson Joshua Creighton</td>\n","      <td>male</td>\n","      <td>30.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>135.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n","      <td>female</td>\n","      <td>25.0000</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>135.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1305</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zabour, Miss. Thamine</td>\n","      <td>female</td>\n","      <td>14.5000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2665</td>\n","      <td>14.4542</td>\n","      <td>F38</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>328.0</td>\n","      <td>Antwerp, Belgium / Stanton, OH</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zakarian, Mr. Mapriededer</td>\n","      <td>male</td>\n","      <td>26.5000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2656</td>\n","      <td>7.2250</td>\n","      <td>F38</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>304.0</td>\n","      <td>Antwerp, Belgium / Stanton, OH</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zakarian, Mr. Ortin</td>\n","      <td>male</td>\n","      <td>27.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2670</td>\n","      <td>7.2250</td>\n","      <td>F38</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>304.0</td>\n","      <td>Antwerp, Belgium / Stanton, OH</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zimmerman, Mr. Leo</td>\n","      <td>male</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>315082</td>\n","      <td>7.8750</td>\n","      <td>F38</td>\n","      <td>S</td>\n","      <td>C</td>\n","      <td>304.0</td>\n","      <td>Antwerp, Belgium / Stanton, OH</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Zimmerman, Mr. Leo</td>\n","      <td>male</td>\n","      <td>29.0000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>315082</td>\n","      <td>7.8750</td>\n","      <td>F38</td>\n","      <td>S</td>\n","      <td>C</td>\n","      <td>304.0</td>\n","      <td>Antwerp, Belgium / Stanton, OH</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1310 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["      pclass  survived  ...   body                        home.dest\n","0        1.0       1.0  ...    NaN                     St Louis, MO\n","1        1.0       1.0  ...    NaN  Montreal, PQ / Chesterville, ON\n","2        1.0       0.0  ...    NaN  Montreal, PQ / Chesterville, ON\n","3        1.0       0.0  ...  135.0  Montreal, PQ / Chesterville, ON\n","4        1.0       0.0  ...  135.0  Montreal, PQ / Chesterville, ON\n","...      ...       ...  ...    ...                              ...\n","1305     3.0       0.0  ...  328.0   Antwerp, Belgium / Stanton, OH\n","1306     3.0       0.0  ...  304.0   Antwerp, Belgium / Stanton, OH\n","1307     3.0       0.0  ...  304.0   Antwerp, Belgium / Stanton, OH\n","1308     3.0       0.0  ...  304.0   Antwerp, Belgium / Stanton, OH\n","1309     3.0       0.0  ...  304.0   Antwerp, Belgium / Stanton, OH\n","\n","[1310 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"KTFGrhLPjHTK","executionInfo":{"status":"aborted","timestamp":1621359931502,"user_tz":-180,"elapsed":3596,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Challenge 8: Government Project Dataset\n","# Onto our other dataset, let's now fill forward the missing values and see what happens\n","# \n","df_fill_forward1 = gov_dataset.fillna(method='ffill')\n","df_fill_forward1\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhKnRkirk-13"},"source":["**Challenge 9: **Together with your peer discuss the cases where you might use the above fill forward technique."]},{"cell_type":"markdown","metadata":{"id":"cp-NTai_33x6"},"source":["### c) We can fill backward missing values"]},{"cell_type":"markdown","metadata":{"id":"9tCj_qF0UdK2"},"source":["We can also do the opposite, and fill data backward our missing values. When doing this, the newest value replaces the missing data."]},{"cell_type":"code","metadata":{"id":"emdfItSJViLy","executionInfo":{"status":"aborted","timestamp":1621359931504,"user_tz":-180,"elapsed":3580,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Again first lets preview df (last 10 items), and note the missing data in the boat and body columns\n","#\n","print(df.tail(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3lUQSTPUtna","executionInfo":{"status":"aborted","timestamp":1621359931506,"user_tz":-180,"elapsed":3574,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# And now fill backward\n","#\n","df_fill_backward = df.fillna(method='bfill')\n","\n","# Then preview our dataframe (last 10 items) and try to understand what took place\n","#\n","print(df_fill_backward.tail(10))\n","\n","# After this, we will discuss what happens when a column ends with a missing value."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jf_uQkE-jUZB","executionInfo":{"status":"aborted","timestamp":1621359931508,"user_tz":-180,"elapsed":3568,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Challenge 10: Government Project Dataset\n","# Back to our government dataset. We now fill backward the missing values \n","# and try to understand the changes that took place\n","# \n","df_fill_backward1 = gov_dataset.fillna(method='bfill')\n","print(df_fill_backward1.tail(10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_PIG0u78lKe-"},"source":["**Challenge 11: ** Together with your peer discuss the cases where you might use the above fill backward technique."]},{"cell_type":"markdown","metadata":{"id":"QdrSkHEP35t5"},"source":["\n","### d) We can interpolate missing values"]},{"cell_type":"markdown","metadata":{"id":"pVDrZtZSXewN"},"source":["Interpolation uses other values to fill in the missing values. It does this by treating missing values as if they should be equally spaced apart. This function fills in the missing values linearly as shown in the example below."]},{"cell_type":"code","metadata":{"id":"J4TIJ5OxYKdj","executionInfo":{"status":"aborted","timestamp":1621359931509,"user_tz":-180,"elapsed":3549,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Once again first lets print out df, and note the missing data in the boat and body columns\n","# NB: iloc gets rows (or columns) at particular positions in the index\n","#\n","df.iloc[0:10, 11:13].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7Fti2xIXq1a","executionInfo":{"status":"aborted","timestamp":1621359931511,"user_tz":-180,"elapsed":3531,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Then perform our intepolation\n","#\n","df_interpolate = df.interpolate().iloc[0:10, 11:13];\n","df_interpolate.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fESIpX-kRfF","executionInfo":{"status":"aborted","timestamp":1621359931512,"user_tz":-180,"elapsed":3515,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Challenge 12: Government Project Dataset\n","# Intepolate the missing values in our dataset, noting the changes\n","#\n","gov_dataset_interpolate = gov_dataset.interpolate().iloc[0:10, 11:13];\n","gov_dataset_interpolate.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7g7vkwiwlPNE"},"source":["**Challenge 13: **Together with your peer discuss the cases where you might use the above interpolate technique."]},{"cell_type":"markdown","metadata":{"id":"Zohn05Kl37a3"},"source":["### e) We can drop/delete missing values"]},{"cell_type":"markdown","metadata":{"id":"kiRRtN2NZxHm"},"source":["The other way to work with missing data is to drop/delete the records with the missing data. This is a judgement that you have to make based on your research. Sometimes keeping the entire dataset together with the missing values, can leave you with a useless dataset. On the other hand, the missing data many not be random and dropping those missing values would leave you with a biased dataset or deleting the missing dataset might leave you with insufficient data for analysis. All of this we will learn more indepth during the course of the program. \n","\n","For now lets see how we can drop missing values from a dataset."]},{"cell_type":"code","metadata":{"id":"HvKBpbSVZq3X","executionInfo":{"status":"aborted","timestamp":1621359931513,"user_tz":-180,"elapsed":3507,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Let's find out the size of our dataset\n","# \n","df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzPYCUtddJJn","executionInfo":{"status":"aborted","timestamp":1621359931514,"user_tz":-180,"elapsed":3498,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# If we were to keep our complete rows; meaning we drop any record with a missing value, then\n","#\n","df_dropped = df.dropna()\n","\n","# We are left with no rows of data\n","#\n","df_dropped.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOZ80EPSdzGI","executionInfo":{"status":"aborted","timestamp":1621359931515,"user_tz":-180,"elapsed":3481,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Printing out df_dropped\n","df_dropped"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAazAAGHgFkP","executionInfo":{"status":"aborted","timestamp":1621359931516,"user_tz":-180,"elapsed":3471,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["# Challenge 14: Financial Allocation Dataset\n","# Let's now drop the records that have missing values\n","url = 'http://bit.ly/MSFinancialDataset'\n","#\n","df1=pd.read_csv(url)\n","df1.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9iN2rc3m2FLq","executionInfo":{"status":"aborted","timestamp":1621359931518,"user_tz":-180,"elapsed":3455,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["df1.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y80Acoy52NsA","executionInfo":{"status":"aborted","timestamp":1621359931519,"user_tz":-180,"elapsed":3452,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["df1_dropped = df1.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQeIQHRa2XRA","executionInfo":{"status":"aborted","timestamp":1621359931520,"user_tz":-180,"elapsed":3442,"user":{"displayName":"Raymond Kiplangat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCuhWKtkM8UYW-JVZw3DvsRDJpjk2DwMOHGMgA=s64","userId":"01120465740264942012"}}},"source":["df1_dropped.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h5AGA9relVMf"},"source":["Challenge 15: Together with your peer discuss the cases where you might use the above drop/delete technique."]}]}